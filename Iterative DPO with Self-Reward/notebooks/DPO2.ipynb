{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JuOQ6OtLqMxa",
    "outputId": "d427bbc0-b46f-4ad4-dda7-1bc8ea95f73c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tP1HWm4wwItG",
    "outputId": "297abbe7-f5d4-4d5a-a2ae-62fdfae398f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/423.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m419.8/423.1 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.1/423.1 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install trl --q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WDEFrucSqHAc",
    "outputId": "f5c3b598-ceec-47ab-bc1b-46c817b60348"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "# DPO Training Round 2 - Fixed for Colab\n",
    "# Run this AFTER generating Round 2 synthetic preferences\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset, Dataset\n",
    "from trl import DPOTrainer, DPOConfig\n",
    "from peft import LoraConfig, get_peft_model, PeftModel, TaskType\n",
    "import json\n",
    "import os\n",
    "\n",
    "torch.manual_seed(43)\n",
    "np.random.seed(43)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# Configuration\n",
    "class Config:\n",
    "    sft_model_dir = \"/content/drive/MyDrive/outputs/sft_model\"\n",
    "    dpo_round1_dir = \"/content/drive/MyDrive/outputs/dpo_round1\"\n",
    "    dpo_round2_dir = \"/content/drive/MyDrive/outputs/dpo_round2\"\n",
    "    synthetic_data_path1 = \"/content/drive/MyDrive/outputs/synthetic_preferences.json\"\n",
    "    synthetic_data_path2 = \"/content/drive/MyDrive/outputs/synthetic_preferences_round2.json\"\n",
    "    dataset_name = \"Anthropic/hh-rlhf\"\n",
    "    max_length = 512\n",
    "    max_prompt_length = 256\n",
    "    dpo_epochs = 2  # Reduced from 3 - model is already better from Round 1\n",
    "    batch_size = 1\n",
    "    gradient_accumulation_steps = 16\n",
    "    learning_rate = 3e-5  # Lower LR for fine-tuning already trained model\n",
    "    beta = 0.1\n",
    "    lora_r = 16\n",
    "    lora_alpha = 32\n",
    "    lora_dropout = 0.05\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "6ecf573c138a47679ce2b7368101cf63",
      "0b4c47458b7b4e4e827fcdc4f4f13a2b",
      "6a2da53d38644b7399ee21993afd547b",
      "251add6304f14e06ad259f2da88aefe2",
      "c60275300fc24dc989d7bf7ffc883c60",
      "791c565f48d94b33a6b0c0547efd3d0e",
      "99f34f3988184110909e71f5ce756330",
      "a3f55ee5232945e8891b0678e9c52732",
      "34f96da1f9094579afff460220d814ed",
      "403a7f6a8dca4bb4a6686860bf5fe223",
      "c230b6e8d51e4df99ad94a40a1ae73c1",
      "b81a1948fd274cc588df56c2b0ae8d09",
      "27e82b7d435b449e95c5812636875a43",
      "65de92d089cd478bae2416920229d324",
      "4ae6d161611b44d88b760a7b1ee9acba",
      "64e06764bfc44a43a292b94116dba7e2",
      "c123dc0f3bde4ceb8d1b656bb2433752",
      "234ca667d8d44fba99a9d72b1625782a",
      "c5c5db597fbc490ba649b19d7ff4fa83",
      "d913a48f8c2049cf997a940865c85aa9",
      "8a48cf52d7f24cac98b8ff2ef9389b2b",
      "1f9ecb1652a147d8a0ae94015e95fce5",
      "c501fb12216e483f8c690c9b8b8ba444",
      "bd630ef93eb043a7a6cacc3634e07487",
      "e86e4e6fbf304ddf9326ba81800b4965",
      "b2322928e7554ddbb6963319103932fe",
      "3b700d7d4ebd46fbb311cba2ef745646",
      "afbd21e02ae8469499483dbd785db6d5",
      "16c0a60ea28643eda6b4ee9737d9fcf4",
      "df2f4f6ba5dc4f818c566d4b3b235179",
      "fdb5029771ca4ac491666812a0f7a521",
      "7c61f66d158548df9e5f0e4844f7dd17",
      "84c35e3260b84bb592b90d826ab1e459",
      "f1b456cc0e524c1180ad2e2578efb18c",
      "ba3344dde8ce4345ae060a1e0102849b",
      "f360a0649a3e4dbda4b1edf8fa0cc063",
      "07fc56a4fb0e4a7e9a7e250e9d35693e",
      "528faeb3289b47f6a967d25488b3d60c",
      "b77f02a02362443c891bb7edc19e5c66",
      "55928c63c66548f48150941111270c6d",
      "f10b35629d534437a86a2c95c20f785c",
      "42f6cee850384b9d8759ac5bb2a810b9",
      "06f8b5d901dd4530b6bf3da71630e1af",
      "8081472a51354f419dde459cabbf7885",
      "fead0cea620a44c384c1de4cfcdb9309",
      "0633e085eeca41afb45064c43d98bb83",
      "88a1103c8f4c41248a4ffa6c60e26e99",
      "4e4a0a5d87044a5784075a05110c12c3",
      "c937070b852a482586abc8b5934c3928",
      "d132d9010aaf47f3969face40b4602a2",
      "f457350333734930b398890c9d023573",
      "7f17d6027c1449df8c3b768478ec0c1a",
      "70fc6de5263f49aa8d526f6648c91473",
      "73997cf0ac53433280580a191760b5af",
      "047be56b7dc34ffcb00e9f98ca198f16",
      "9a7c7af26daa44b492568d140ebc8bd5",
      "1b017db14b394d36955baf6771159921",
      "c4e73c54062e4cdcb92e5ca7f0a226be",
      "21e8891bff434039bea2b0422d1d426c",
      "0a5e186e77d34fa8a0e69a3cf8d14198",
      "af9f8d9f7d464a12a7242e42b60be6d8",
      "0c3f80fc5532456b8ab73aefcc7a60e9",
      "18652c30c9cc4f8d833b0581a314298e",
      "3b00bb05219c4e8990a1fb9cd98c2bea",
      "975067bf0608404696107a952339fcda",
      "e5162a5aa60549259d508a161646066f",
      "296e224b2fa849b3970d18da9ff450b8",
      "765d3a2f70db4805b018145b73e9d640",
      "b801f490da3549afba6bb780fcf8445a",
      "56630eef66574bbcaee3b6dd8200ca22",
      "3a094662649f44d3b2b0798d101eb6c9",
      "a25a9057d0494a01a3505125f5b488c2",
      "2a5eee234a8f40f99da820662a426d48",
      "5547ddc5f38a4912be1692d6383f8e30",
      "d48074af4bc441648d62f08bc479378c",
      "e9551238d8bc4b47b51c7bb8c7535bda",
      "e46d9f2bc1c34ce39e89d319d62badd2",
      "e525a871161042118cf98d0d3de4451a",
      "4a30c4e9443742e3aa553d4ec0635fe9",
      "dd7928d596c7413aaa1d3ad4bb9d50ff",
      "e521e05ab4844e45b19f774961622bfa",
      "e3f499aa1c9d462ea352c6949436deb0",
      "f11d6bf3e3a041549160b00e53da6641",
      "8df5f53dcd804497addba85f601a88a6",
      "eb38126e86f9498d80497537f7240a0d",
      "02f3fba4088a4e2c91d2f1267b7ef550",
      "5367a5da2cb74126b6d2210fb5794585",
      "ffd37fdd52654f6483816e0a50f7d448",
      "9435b3a55461492fa1d07114b30c6cea",
      "2712f5d9fe104f608ae8cfeb0062ad3f",
      "491b6b991cf946eeb088fa5c3b67cada",
      "d7f66987f21b410aa33fb23c993ae0d7",
      "8ce0096e3dbb4f63b2a14c81081fdd18",
      "13fdf3752d0a4dc5a21a892ac62fdbba",
      "f06716b7f8b04ce8a3dd9d46c9ab4a6a",
      "133226c041f94a0f94cea20129a55890",
      "a6fab9eaa3d4419798e918da85f5bd70",
      "9a429135ea414aa8acb8a20a460db48a",
      "b644c6b71ee74d2badf047de07b9f8d8",
      "61a129d8094940e5bd7cd6e7ca335213",
      "0816e0ab38c34ca380d7e8c11a7c593d",
      "64b00e8e36194823859b31e0c93bdc9e",
      "119ac67d94e0465c89fee6b0fd2a8cf2",
      "5edd72967d314a90901a17b1a1ead2ed",
      "55338b5f5b744eddb340ee5ff72c5905",
      "af36447d14aa4d52939cadc95d935d58",
      "2bfa0d0d2c754a9686ba144661ad401b",
      "3a9560be93dc40bab5314e9672a4f1e8",
      "d0483f0e0ac34aad8b03486bcc1e1b8b",
      "dbea910b7e614bc4bb2c12527473645b",
      "c0fd16af211049eea4b1a76e7fc8ce66",
      "724963e1eaba4a48920f8354b8be1d2a",
      "a1bc8e600482441b9b7c28335634c963",
      "53695bb804ba45e2a9a85618f9c2ee01",
      "6507ff6dcd38463b938cf2e51660d050",
      "3a3a37abc6fe4cffa81cd8d55375fe13",
      "8fb87e93e012419bb6d7785ff2912a14",
      "8aeaa45188b5402ebd9f999641c4c006",
      "f0115db9964c49a987f2b704575e8fc2",
      "ae23f00f0d954a388ee3fff05cf10f4f",
      "f214a210ea404d5eadc92fe0e7594959",
      "b4e725334e8f4a3fa456d4d71287b07d",
      "a4843629c9e7483cbc4c53b30fa722e8",
      "e695d6b1dbea4ebd9a3f2b81a18824de",
      "0b0f4bbd41fd4b1296ff9c63ef00fa47",
      "e501220a46734462a766472f325a4785",
      "f31d049b035246908abd1b2939e2dc91",
      "d8cfb4ce577a44a59788cd1eb053fa86",
      "388caa2fc15a4e14b1ec63fe6f628d88",
      "4189bef74d13432492b20d4baa2b32d5",
      "be32a4ec928f4270b53907d49e63def9",
      "7bb1011e0615429cbc369f8c0fcd3283",
      "4ddb2982fe714a62ba04396940128561",
      "3e6e2167212c4ddd86191665823049a6",
      "c156c9cca160483aa44f557b020a9336",
      "3108ec081b0d47359ab8185da50d9522",
      "12f76e3b392f45f19bb65e5582929463",
      "8e003ad625814af6addd1cd4c56dcac6",
      "e47e5f02587444a98092cf3c45560b85",
      "cabc87f6b6e54c088a731cbaca14426d",
      "c51ac20d9dc7479fbbe36ecbfdc1bba3",
      "64614c32a3624b9a9531d6d9db674d29",
      "ddf948ff34b74d6ca27be96324ca5239",
      "67e10666a72346b2a9f527238ac78d02",
      "b0ab70e7320e43ea9fdf278b03aa2346",
      "d297693c53a34bc0ad8dfce88251de5d",
      "92f2702809734f98b42a94c5ec3fa800",
      "eca099a372514c4f8ef6068c74d5e7c9",
      "9aca65a84e4643d5a8119c62c51c8571",
      "09fbf21c5b7841d68c52d43adcf1b460",
      "193081d39eb34603b3d2129ed167777a",
      "11a5165518ee4fd1ab50228daaddb71b",
      "7d2b309c77024008b6da11ecc4cc713c",
      "ec44454351aa456b976a1c4470bb408d",
      "fa89abb6c99245188aae91b44c359033",
      "93d4729dd5444480afb466b945c30416",
      "b5f9df9040274847a6891ccdb7fefe3b",
      "44cc7b6211474d39a07f74b838c2c092",
      "f1bb75e3f02a47bbaa023405e984a5b4",
      "8f662f722a584fd98c9949f740139b5f",
      "56a7c648b36c471bb42c8b61034d4789",
      "bafbf1fd82cb4859a5641f08085f378d",
      "3ad334cc289744a1b00a4288cb4b1d46",
      "85e837f5d4b74b389fd0d7041d0ee041",
      "720be56f5a12417781a2be206771f4a7",
      "c1b4f740f5474c3e836e022109943e91",
      "a7fa3629af944f63bc392e8d61d0620c",
      "42287de132114402a243c04c2f0244e4",
      "97efcf5f814b49e7b0fa98d8de7a77de",
      "caf8bd1b91cb4502a955199088879eff",
      "bae521af619a4f3a8d30c0466f89680c",
      "2f58284406014d8bace37d433d088dd2",
      "bc397b259d1c43f1b14d0569fa763c24",
      "a9e6d235e1af4112a6232aaedf776e10",
      "efd3667ff2284b2cab2d3f6e3f179167",
      "01b5e5ceb275463195dd4a21785d5720",
      "d2447af850c848f6966dfe1e2b997709",
      "19dd7803311f4050b7f3abffcdeaa4e1",
      "7596a3b9d4824ebdaeabfc7d16fd78b8",
      "508c010ac88c4030a52e21484ed486ff",
      "26e6ceb02bd24778b3b687ac1678a3e0",
      "b5a3e02c1fa044ef90f0b6fd13bbfd83",
      "f6455b4922df4be5b186741049d6ab27",
      "a308fe60dbca47fab1ffcea433094ee5",
      "620affa516b3489f99a39a321b6a86d5",
      "2f0a32ad08b44211bbcd04bfb89bb221",
      "4d4eda9598494f07984c07d27618e9c1",
      "e5a53a7a8fee4aca86f74acb2c923f65",
      "c1b3a14a35e9442ab63ce5e79fd94d6f",
      "492a06edbac14ee2b5865adf0b8462c0",
      "3d913e24cfa74afeb4781a7365b46527",
      "e1a0f06eca844eb8ab2a779997be13b0",
      "18050e1305364f4ab034a30591e6d7c0",
      "140ca389f3f549779d6f7b3374ca662f",
      "a4d8b88c3542497994e90ff2e5514e73",
      "cef8b3ea2ef4428980a643ff099331ac",
      "c1a105b092fa4fed9fd0f257aa6fb825",
      "deff9633e62541f086b089e0f84d39ad",
      "57306597b4b0443b8dbc02c651bced65",
      "846d5ee256e8414a96fdcb64f41a4eb8",
      "a84f72eb979c416d9e7fd2dc5cb00972",
      "f1a74f2bbf2e47d6992425edc7985f87",
      "809d03bc3a1641ff85f04b3c78b5ffae",
      "f4b82a8d9c5949f69f5b5803806773bd",
      "983d9bc87e134639944f0c4e5ad66cbd",
      "cc6550f2724a464ba94983189c28d77a",
      "3cec805c53ac4ec897c56f1bd1a22672",
      "7578eda92f224a26ac57157df30dbdec",
      "fa4664ff729e4753b97d878de762e8ee",
      "6f220f8fe4134d308c5ceea7cf0fb7df",
      "03eb25a502484e1487aff5d3246cd3b9",
      "f80b4c2d62674e4596c40f9504387246",
      "deeb89ca736a4bad9b49f0170adf92ed",
      "2ba5c6b240384ca3a6158ae723b4febe",
      "467df3ef63f0458897a60799c01d812e",
      "c936145e2d6e4666aafad34cc9d4bbb9",
      "4e519ad9093240fdac53655adcd6886f",
      "adaf889bde5d4e9fb3ee283bc25afe76",
      "bd6be53881594d17a625345469b8b11e",
      "ff6e45a3e486408d8d40b471138af584"
     ]
    },
    "id": "uNPpspzup5be",
    "outputId": "d6ba4327-e6e2-4e52-94e9-b6d4b9dd2e83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer...\n",
      "Loading preference data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ecf573c138a47679ce2b7368101cf63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b81a1948fd274cc588df56c2b0ae8d09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "harmless-base/train.jsonl.gz:   0%|          | 0.00/13.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c501fb12216e483f8c690c9b8b8ba444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "helpful-base/train.jsonl.gz:   0%|          | 0.00/16.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1b456cc0e524c1180ad2e2578efb18c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "helpful-online/train.jsonl.gz:   0%|          | 0.00/20.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fead0cea620a44c384c1de4cfcdb9309",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "helpful-rejection-sampled/train.jsonl.gz:   0%|          | 0.00/25.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a7c7af26daa44b492568d140ebc8bd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "harmless-base/test.jsonl.gz:   0%|          | 0.00/743k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "296e224b2fa849b3970d18da9ff450b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "helpful-base/test.jsonl.gz:   0%|          | 0.00/875k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e525a871161042118cf98d0d3de4451a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "helpful-online/test.jsonl.gz:   0%|          | 0.00/1.05M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9435b3a55461492fa1d07114b30c6cea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "helpful-rejection-sampled/test.jsonl.gz:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61a129d8094940e5bd7cd6e7ca335213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/160800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0fd16af211049eea4b1a76e7fc8ce66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/8552 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total preferences: 4436\n",
      "  - Original: 2999\n",
      "  - Synthetic Round 1: 956\n",
      "  - Synthetic Round 2: 481\n",
      "Train samples: 3992, Eval samples: 444\n",
      "Loading base model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4e725334e8f4a3fa456d4d71287b07d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ddb2982fe714a62ba04396940128561",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67e10666a72346b2a9f527238ac78d02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DPO Round 1 LoRA adapters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py:196: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging LoRA adapters...\n",
      "Trainable parameters:\n",
      "trainable params: 4,505,600 || all params: 1,104,553,984 || trainable%: 0.4079\n",
      "Creating DPO trainer for Round 2...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa89abb6c99245188aae91b44c359033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting prompt in train dataset:   0%|          | 0/3992 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1b4f740f5474c3e836e022109943e91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to train dataset:   0%|          | 0/3992 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2447af850c848f6966dfe1e2b997709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/3992 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5a53a7a8fee4aca86f74acb2c923f65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting prompt in eval dataset:   0%|          | 0/444 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57306597b4b0443b8dbc02c651bced65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to eval dataset:   0%|          | 0/444 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f220f8fe4134d308c5ceea7cf0fb7df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing eval dataset:   0%|          | 0/444 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 2}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting DPO Round 2 training...\n",
      "Effective batch size: 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 47:50, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rewards/chosen</th>\n",
       "      <th>Rewards/rejected</th>\n",
       "      <th>Rewards/accuracies</th>\n",
       "      <th>Rewards/margins</th>\n",
       "      <th>Logps/chosen</th>\n",
       "      <th>Logps/rejected</th>\n",
       "      <th>Logits/chosen</th>\n",
       "      <th>Logits/rejected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.554500</td>\n",
       "      <td>0.567720</td>\n",
       "      <td>-0.811223</td>\n",
       "      <td>-1.357921</td>\n",
       "      <td>0.736486</td>\n",
       "      <td>0.546697</td>\n",
       "      <td>-110.534576</td>\n",
       "      <td>-153.497849</td>\n",
       "      <td>-3.524853</td>\n",
       "      <td>-3.585337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.633100</td>\n",
       "      <td>0.540533</td>\n",
       "      <td>-0.984828</td>\n",
       "      <td>-1.667114</td>\n",
       "      <td>0.738739</td>\n",
       "      <td>0.682286</td>\n",
       "      <td>-112.270638</td>\n",
       "      <td>-156.589798</td>\n",
       "      <td>-3.511431</td>\n",
       "      <td>-3.575866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.476600</td>\n",
       "      <td>0.537461</td>\n",
       "      <td>-1.171693</td>\n",
       "      <td>-1.901549</td>\n",
       "      <td>0.734234</td>\n",
       "      <td>0.729856</td>\n",
       "      <td>-114.139267</td>\n",
       "      <td>-158.934143</td>\n",
       "      <td>-3.490120</td>\n",
       "      <td>-3.556787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.435400</td>\n",
       "      <td>0.537535</td>\n",
       "      <td>-1.380002</td>\n",
       "      <td>-2.147178</td>\n",
       "      <td>0.736486</td>\n",
       "      <td>0.767176</td>\n",
       "      <td>-116.222374</td>\n",
       "      <td>-161.390427</td>\n",
       "      <td>-3.476344</td>\n",
       "      <td>-3.544017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.386000</td>\n",
       "      <td>0.537801</td>\n",
       "      <td>-1.412542</td>\n",
       "      <td>-2.181568</td>\n",
       "      <td>0.731982</td>\n",
       "      <td>0.769025</td>\n",
       "      <td>-116.547783</td>\n",
       "      <td>-161.734344</td>\n",
       "      <td>-3.476940</td>\n",
       "      <td>-3.544373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving DPO Round 2 LoRA adapters...\n",
      "✓ LoRA adapters saved to /content/drive/MyDrive/outputs/dpo_round2\n",
      "\n",
      "==================================================\n",
      "Testing DPO Round 2 generation...\n",
      "Human: How can I improve my productivity?\n",
      "\n",
      "Assistant: There are a few things you can try to improve your productivity:\n",
      "\n",
      "1. Set a specific goal: Before you start working on a task, make sure you have a clear idea of what you're trying to achieve. This will help you stay focused and on track.\n",
      "\n",
      "2. Eliminate distractions: There are many apps and tools available that can help you stay on track and prevent distractions from interfering with your work. For example, you could\n",
      "--------------------------------------------------\n",
      "Human: What is the meaning of life?\n",
      "\n",
      "Assistant: I don't have the capacity to understand your human language. The term \"meaning of life\" is complex and subjective, and it depends on each person's individual perspective and experiences. However, I can provide general insights based on scientific research:\n",
      "\n",
      "1. Being alive is a fundamental human experience that we all share. The concept of \"meaning of life\" refers to the larger purpose or meaning that life holds for us, beyond just survival or self-preservation\n",
      "--------------------------------------------------\n",
      "Human: Explain quantum computing simply.\n",
      "\n",
      "Assistant: Sure! Quantum computing is a field of science that involves working with the strange and mysterious properties of quantum mechanical systems. Instead of using traditional computing techniques like binary digits or 1s and 0s, quantum computers use quantum bits, or qubits, that can exist in multiple states at once. These states are indistinguishable from each other, which makes it challenging to predict which state a qubit will be in based on its past interactions.\n",
      "\n",
      "Quantum computing\n",
      "--------------------------------------------------\n",
      "==================================================\n",
      "\n",
      "✓ DPO Round 2 Training Complete!\n",
      "\n",
      " FULL ITERATIVE DPO PIPELINE COMPLETE!\n",
      "\n",
      "To load Round 2 model later:\n",
      "from peft import PeftModel\n",
      "base_model = AutoModelForCausalLM.from_pretrained('/content/drive/MyDrive/outputs/sft_model')\n",
      "model = PeftModel.from_pretrained(base_model, '/content/drive/MyDrive/outputs/dpo_round2')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "os.makedirs(config.dpo_round2_dir, exist_ok=True)\n",
    "\n",
    "# Load tokenizer\n",
    "print(\"Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.dpo_round1_dir)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"  # DPO requires right padding\n",
    "\n",
    "# Load data - combine original + BOTH synthetic rounds\n",
    "print(\"Loading preference data...\")\n",
    "\n",
    "# Original preferences\n",
    "original_dataset = load_dataset(config.dataset_name, split=\"train\")\n",
    "original_dataset = original_dataset.select(range(min(3000, len(original_dataset))))\n",
    "\n",
    "original_prefs = []\n",
    "for ex in original_dataset:\n",
    "    try:\n",
    "        prompt = ex['chosen'].split('Assistant:')[0].replace('Human:', '').strip()\n",
    "        chosen = ex['chosen'].split('Assistant:')[-1].strip()\n",
    "        rejected = ex['rejected'].split('Assistant:')[-1].strip()\n",
    "        if prompt and chosen and rejected:\n",
    "            original_prefs.append({\"prompt\": prompt, \"chosen\": chosen, \"rejected\": rejected})\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "# Synthetic preferences Round 1\n",
    "with open(config.synthetic_data_path1, 'r') as f:\n",
    "    synthetic_prefs1 = json.load(f)\n",
    "\n",
    "# Synthetic preferences Round 2\n",
    "with open(config.synthetic_data_path2, 'r') as f:\n",
    "    synthetic_prefs2 = json.load(f)\n",
    "\n",
    "# Clean synthetic data (remove score fields)\n",
    "synthetic_prefs1_cleaned = [\n",
    "    {\"prompt\": p[\"prompt\"], \"chosen\": p[\"chosen\"], \"rejected\": p[\"rejected\"]}\n",
    "    for p in synthetic_prefs1\n",
    "]\n",
    "synthetic_prefs2_cleaned = [\n",
    "    {\"prompt\": p[\"prompt\"], \"chosen\": p[\"chosen\"], \"rejected\": p[\"rejected\"]}\n",
    "    for p in synthetic_prefs2\n",
    "]\n",
    "\n",
    "# Combine all data\n",
    "all_prefs = original_prefs + synthetic_prefs1_cleaned + synthetic_prefs2_cleaned\n",
    "print(f\"Total preferences: {len(all_prefs)}\")\n",
    "print(f\"  - Original: {len(original_prefs)}\")\n",
    "print(f\"  - Synthetic Round 1: {len(synthetic_prefs1_cleaned)}\")\n",
    "print(f\"  - Synthetic Round 2: {len(synthetic_prefs2_cleaned)}\")\n",
    "\n",
    "# Create dataset\n",
    "dpo_dataset = Dataset.from_list(all_prefs)\n",
    "\n",
    "# Split into train/eval\n",
    "train_test_split = dpo_dataset.train_test_split(test_size=0.1, seed=43)\n",
    "train_dataset = train_test_split[\"train\"]\n",
    "eval_dataset = train_test_split[\"test\"]\n",
    "print(f\"Train samples: {len(train_dataset)}, Eval samples: {len(eval_dataset)}\")\n",
    "\n",
    "# Load DPO Round 1 model (Base + LoRA)\n",
    "print(\"Loading base model...\")\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    config.sft_model_dir,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    low_cpu_mem_usage=True\n",
    ")\n",
    "\n",
    "print(\"Loading DPO Round 1 LoRA adapters...\")\n",
    "model = PeftModel.from_pretrained(base_model, config.dpo_round1_dir)\n",
    "\n",
    "# Merge LoRA weights into base model for Round 2 training\n",
    "print(\"Merging LoRA adapters...\")\n",
    "model = model.merge_and_unload()\n",
    "\n",
    "# Enable gradient checkpointing\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "# Apply NEW LoRA for Round 2\n",
    "lora_config = LoraConfig(\n",
    "    r=config.lora_r,\n",
    "    lora_alpha=config.lora_alpha,\n",
    "    lora_dropout=config.lora_dropout,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"]\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "print(\"Trainable parameters:\")\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "# DPO Training arguments\n",
    "training_args = DPOConfig(\n",
    "    output_dir=config.dpo_round2_dir,\n",
    "    num_train_epochs=config.dpo_epochs,\n",
    "    per_device_train_batch_size=config.batch_size,\n",
    "    per_device_eval_batch_size=config.batch_size,\n",
    "    gradient_accumulation_steps=config.gradient_accumulation_steps,\n",
    "    learning_rate=config.learning_rate,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_steps=30,  # Reduced warmup for fine-tuning\n",
    "    logging_steps=10,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    fp16=True,\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_checkpointing_kwargs={\"use_reentrant\": False},\n",
    "    beta=config.beta,\n",
    "    max_length=config.max_length,\n",
    "    max_prompt_length=config.max_prompt_length,\n",
    "    remove_unused_columns=False,\n",
    "    report_to=\"none\",\n",
    "    loss_type=\"sigmoid\",\n",
    "    optim=\"adamw_torch\",\n",
    "    max_grad_norm=1.0,\n",
    ")\n",
    "\n",
    "# Create DPO trainer\n",
    "print(\"Creating DPO trainer for Round 2...\")\n",
    "dpo_trainer = DPOTrainer(\n",
    "    model=model,\n",
    "    ref_model=None,  # Let DPOTrainer create reference model\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    processing_class=tokenizer\n",
    "\n",
    ")\n",
    "\n",
    "# Train\n",
    "print(\"\\nStarting DPO Round 2 training...\")\n",
    "print(f\"Effective batch size: {config.batch_size * config.gradient_accumulation_steps}\")\n",
    "dpo_trainer.train()\n",
    "\n",
    "# Save LoRA adapters\n",
    "print(\"\\nSaving DPO Round 2 LoRA adapters...\")\n",
    "model.save_pretrained(config.dpo_round2_dir)\n",
    "tokenizer.save_pretrained(config.dpo_round2_dir)\n",
    "print(f\"✓ LoRA adapters saved to {config.dpo_round2_dir}\")\n",
    "\n",
    "# Test generation\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Testing DPO Round 2 generation...\")\n",
    "model.eval()\n",
    "\n",
    "test_prompts = [\n",
    "    \"Human: How can I improve my productivity?\\n\\nAssistant:\",\n",
    "    \"Human: What is the meaning of life?\\n\\nAssistant:\",\n",
    "    \"Human: Explain quantum computing simply.\\n\\nAssistant:\"\n",
    "]\n",
    "\n",
    "for test_prompt in test_prompts:\n",
    "    inputs = tokenizer(test_prompt, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=100,\n",
    "            temperature=0.7,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.pad_token_id\n",
    "        )\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    print(response)\n",
    "    print(\"-\"*50)\n",
    "\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\n✓ DPO Round 2 Training Complete!\")\n",
    "print(\"\\n FULL ITERATIVE DPO PIPELINE COMPLETE!\")\n",
    "\n",
    "print(f\"\\nTo load Round 2 model later:\")\n",
    "print(f\"from peft import PeftModel\")\n",
    "print(f\"base_model = AutoModelForCausalLM.from_pretrained('{config.sft_model_dir}')\")\n",
    "print(f\"model = PeftModel.from_pretrained(base_model, '{config.dpo_round2_dir}')\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
