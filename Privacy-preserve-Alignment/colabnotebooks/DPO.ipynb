{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tWtbVqUwI1Eg"
   },
   "source": [
    "# notebooks/1_dpo_track.ipynb\n",
    "\n",
    "\"\"\"\n",
    "Project 4: Privacy-Preserving Alignment\n",
    "Notebook 1: DPO Track (All DPO Variants)\n",
    "\n",
    "Purpose: Train all DPO models (baseline + DP variants)\n",
    "Optimized: MAX_LENGTH=224 (5.2x faster, 96.7% coverage)\n",
    "Time: ~40 minutes on T4 (vs 3-4 hours original)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aibHX9rsI6aJ",
    "outputId": "59e67c66-f48b-40d0-f531-616550528f9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      " Google Drive mounted successfully!\n"
     ]
    }
   ],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "if os.path.exists('/content/drive/MyDrive'):\n",
    "    print(\" Google Drive mounted successfully!\")\n",
    "else:\n",
    "    print(\" Drive mount failed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0iTRd2LiLFoc",
    "outputId": "aef408a2-2f9b-4040-b40e-a6287cb20e95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/423.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.1/423.1 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/254.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.4/254.4 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers datasets peft trl opacus accelerate  --q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "93-1lfMzI8mw",
    "outputId": "c37f266f-822b-4b03-df34-fa0f1c11bb2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Imports complete\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "import sys\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datasets import load_from_disk\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    prepare_model_for_kbit_training,\n",
    "    TaskType\n",
    ")\n",
    "from trl import DPOTrainer, DPOConfig\n",
    "from opacus import PrivacyEngine\n",
    "from opacus.validators import ModuleValidator\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "import shutil\n",
    "\n",
    "print(\" Imports complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qd68LJiaJAuD",
    "outputId": "dc0980fa-4873-493c-cb1c-b3afce36f75b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Directories configured\n",
      " Data will load from: /content/drive/MyDrive/Project4_Privacy_Alignment/data\n",
      " Models will save to: /content/drive/MyDrive/Project4_Privacy_Alignment/models\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Configure Paths (Drive + Local)\n",
    "# === GOOGLE DRIVE PATHS (PERSISTENT) ===\n",
    "DRIVE_BASE = Path(\"/content/drive/MyDrive/Project4_Privacy_Alignment\")\n",
    "DRIVE_DATA_DIR = DRIVE_BASE / \"data\"\n",
    "DRIVE_MODELS_DIR = DRIVE_BASE / \"models\"\n",
    "DRIVE_RESULTS_DIR = DRIVE_BASE / \"results\"\n",
    "\n",
    "# === LOCAL PATHS (TEMPORARY - FASTER FOR TRAINING) ===\n",
    "LOCAL_BASE = Path(\"/content\")\n",
    "LOCAL_DATA_DIR = LOCAL_BASE / \"data\"\n",
    "LOCAL_MODELS_DIR = LOCAL_BASE / \"models\"\n",
    "LOCAL_RESULTS_DIR = LOCAL_BASE / \"results\"\n",
    "CHECKPOINT_DIR = LOCAL_BASE / \"checkpoints\"\n",
    "\n",
    "# Create directories\n",
    "for dir_path in [LOCAL_DATA_DIR, LOCAL_MODELS_DIR, LOCAL_RESULTS_DIR,\n",
    "                 CHECKPOINT_DIR, DRIVE_MODELS_DIR, DRIVE_RESULTS_DIR]:\n",
    "    dir_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "print(\" Directories configured\")\n",
    "print(f\" Data will load from: {DRIVE_DATA_DIR}\")\n",
    "print(f\" Models will save to: {DRIVE_MODELS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bEQH7M-hJDVv",
    "outputId": "71b6543f-cb84-4dbc-a0a5-ea5c4506bc3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Loading processed data from Google Drive...\n",
      "   Copying from Drive to local (faster for training)...\n",
      " Data loaded from Drive!\n",
      "   Train: 18000 samples\n",
      "   Test: 2000 samples\n",
      "   Device: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load Data from Drive\n",
    "print(\"\\n Loading processed data from Google Drive...\")\n",
    "\n",
    "# Copy from Drive to local (faster for training)\n",
    "drive_dataset_path = DRIVE_DATA_DIR / \"hh_rlhf_processed\"\n",
    "local_dataset_path = LOCAL_DATA_DIR / \"hh_rlhf_processed\"\n",
    "\n",
    "if not drive_dataset_path.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\" Data not found in Drive!\\n\"\n",
    "        f\"Expected: {drive_dataset_path}\\n\"\n",
    "        f\"Please run Notebook 0 first to prepare data.\"\n",
    "    )\n",
    "\n",
    "# Copy to local for faster access\n",
    "if local_dataset_path.exists():\n",
    "    shutil.rmtree(local_dataset_path)\n",
    "\n",
    "print(\"   Copying from Drive to local (faster for training)...\")\n",
    "shutil.copytree(drive_dataset_path, local_dataset_path)\n",
    "\n",
    "# Copy config\n",
    "shutil.copy2(\n",
    "    DRIVE_DATA_DIR / \"config.json\",\n",
    "    LOCAL_DATA_DIR / \"config.json\"\n",
    ")\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_from_disk(str(local_dataset_path))\n",
    "train_dataset = dataset['train']\n",
    "test_dataset = dataset['test']\n",
    "\n",
    "# Load config\n",
    "with open(LOCAL_DATA_DIR / \"config.json\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "print(f\" Data loaded from Drive!\")\n",
    "print(f\"   Train: {len(train_dataset)} samples\")\n",
    "print(f\"   Test: {len(test_dataset)} samples\")\n",
    "print(f\"   Device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388,
     "referenced_widgets": [
      "007863e0a5a4405fb92a45e1b3cab378",
      "532763d4d4c24a94b953a30aca44e7e6",
      "d4e4c2c4c2984263bd50c82b60290c3a",
      "b7c076293822433bb25c7ab7a60f0d52",
      "02a8a5db3b9e4165a771d8d05132df52",
      "b8a683af61b94642afe3be2846ecf844",
      "f2e815f971014b1397726407741aeaff",
      "3ebe44b9036249e39ca77f5456dba421",
      "31d28185b4bd46059b4abef1b2156f25",
      "f91352fd55864a63ae5a0834bd08ac02",
      "b132233733894deeb0dbad491823c0c5",
      "ff44ebbd1eaf47ea8cd26f1bf34eb9a8",
      "ca5d7e36f7554787aaed8c56f40a9dc2",
      "b122d825dc2149808231c218ecbfb329",
      "310dcf90767740a884239c3eef2d4b8d",
      "04b6a913603045a68b48f475cfeca9d2",
      "f1ad6fe07e02469abc09e69df70aa763",
      "343f088a11a04cc6a355134984116123",
      "33586f0639354ef5a3b16f1adfc39291",
      "5871c39758c1457c9629c6ece269da3d",
      "5fec6bf31e7d43bc947725b43366af5b",
      "5c093fa9098b4a6cbb2e5c91b3a92b4a",
      "0cf252f70cef47e0b1dd57905733bdba",
      "d0ba730eb4d04ab6bc7f01d161ea0a5c",
      "96b92feacae74d1faff0e1fe9fd59fc1",
      "95ac0c8cb4d04a9aaee789e7f083ac76",
      "adfa5d6a7181467abd47c8f0937363f7",
      "bafcf333f90448b4b6dbdb7d5ec75259",
      "74f36e640a274b40b840a9ebfff10d4b",
      "5ad5cd5701da4c828ce9823bcb409c8b",
      "424f5ca5cd16437a8cec36cbdb6e7e1a",
      "4ef8b697cd664a1a949278171985d01a",
      "29400bd188d641119789739153a40d38",
      "0526b3126bd94546b9331fddeaf7a931",
      "d543c7cc98034b39bb25b75dc7873d75",
      "d3e1da123167425286be0e29ae9bc9e3",
      "ff940f39923d4f69b49405be44367ee9",
      "5dd7ea0e87074e34a26002f16c3b2544",
      "c55436d587b74b12bd126657d0ebb1ca",
      "2a4695bfc65747858d8dece3fc955901",
      "00a75fc2e9334cf994ff1c61bd0a2ae3",
      "810e1692629848ada1b6a3a4be1e4503",
      "1802ac4ffbb14c7eb1717898ffdee8a2",
      "fc0e6a0788244a51b6ba12fe03bceada",
      "66dd6aa31b7f4f2ba935379de43498bc",
      "ec6f4bf0b14649429ba9e9d337af50ff",
      "fb767c8c262841c18faa28832c968215",
      "86bec7d8cc6645b49eb5ec0a5f7e1864",
      "ca152818a7054d80a16c4242db6ea0dc",
      "760db7d544ce447a815e3eb212edf1be",
      "9de018dfeee447199e4c8644de6fd83b",
      "3c76a91db92d43e986e5d925978bee1b",
      "4007b08677e942b79a4fb2a58f39dd73",
      "7cd878dc3ec2443a81b277583152069e",
      "1de45c0a369248ce8e714a510abe9873"
     ]
    },
    "id": "hza9B6mEJFR-",
    "outputId": "af28fba0-d090-495b-f004-21c261a7cb1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Loading tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "007863e0a5a4405fb92a45e1b3cab378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff44ebbd1eaf47ea8cd26f1bf34eb9a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf252f70cef47e0b1dd57905733bdba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0526b3126bd94546b9331fddeaf7a931",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66dd6aa31b7f4f2ba935379de43498bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tokenizer loaded: gpt2\n",
      "   Vocab size: 50257\n",
      "   MAX_LENGTH: 224 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize Tokenizer with Optimized MAX_LENGTH\n",
    "print(\"\\n Loading tokenizer...\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(config['policy_model'])\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = 'left'  # Important for generation\n",
    "\n",
    "# OPTIMIZED: Use 224 instead of 512\n",
    "MAX_LENGTH = 224  # Covers 96.7% of data, 5.2x faster\n",
    "\n",
    "print(f\" Tokenizer loaded: {config['policy_model']}\")\n",
    "print(f\"   Vocab size: {len(tokenizer)}\")\n",
    "print(f\"   MAX_LENGTH: {MAX_LENGTH} \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 116,
     "referenced_widgets": [
      "437dc400ebab497fb2c1e916f88119ea",
      "e74c3c851a3349cdb3fc161ddfaa606c",
      "99a547dd581745eabc1bd3a530be24a3",
      "a9f09299c9a242459d02c10b97690b59",
      "54153fe17eaa411aa46c261c28ffc431",
      "e82db31bca104329ad78d94142b69294",
      "e1110c5efadc474596b98e5069b31812",
      "29007139200e4d448fb41859e577b65b",
      "369ee3633dd649b4915883ea64642e87",
      "ec477a1d17b649aebd5cd4c4f575de0b",
      "a4616e955aae48d6a61d4d4fba07df75",
      "76137a11631b4d91a66727e86c89e577",
      "cc858aaaa32843ec81166ed51665420c",
      "18fa3af8e9314fdd96ee982923a9855b",
      "9b2ad4e46d43465980bc03eeb7a43455",
      "4a82de52c4c143dea99f7bc5be15b0e9",
      "4e6bc95c870d44c9934a4769a5e6dcdc",
      "92012c78c5ad4b7dbb95a94e9cbc1477",
      "1b532f9430f7412e847efad66ae83b00",
      "2692065f55bd45e8a46d2e813f4e7169",
      "57719ac6537f4944acba04b83bdfcb05",
      "49c78006ea984c44b9936a1f22727ddd"
     ]
    },
    "id": "lzyWi9ReJHkU",
    "outputId": "f22e25a4-b1be-4cf6-f9e0-57907bba6653"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tokenizing dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "437dc400ebab497fb2c1e916f88119ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train:   0%|          | 0/18000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76137a11631b4d91a66727e86c89e577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing test:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tokenization complete\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Tokenize Dataset\n",
    "def tokenize_function(examples):\n",
    "    \"\"\"Tokenize prompts and responses with optimized max_length\"\"\"\n",
    "    prompts = examples['prompt']\n",
    "    chosen = examples['chosen']\n",
    "    rejected = examples['rejected']\n",
    "\n",
    "    # Tokenize with optimized MAX_LENGTH\n",
    "    prompt_tokens = tokenizer(prompts, truncation=True, max_length=MAX_LENGTH)\n",
    "    chosen_tokens = tokenizer(chosen, truncation=True, max_length=MAX_LENGTH)\n",
    "    rejected_tokens = tokenizer(rejected, truncation=True, max_length=MAX_LENGTH)\n",
    "\n",
    "    return {\n",
    "        'input_ids': prompt_tokens['input_ids'],\n",
    "        'attention_mask': prompt_tokens['attention_mask'],\n",
    "        'chosen_input_ids': chosen_tokens['input_ids'],\n",
    "        'rejected_input_ids': rejected_tokens['input_ids'],\n",
    "    }\n",
    "\n",
    "print(\" Tokenizing dataset...\")\n",
    "tokenized_train = train_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=train_dataset.column_names,\n",
    "    desc=\"Tokenizing train\"\n",
    ")\n",
    "tokenized_test = test_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=test_dataset.column_names,\n",
    "    desc=\"Tokenizing test\"\n",
    ")\n",
    "\n",
    "print(\" Tokenization complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CNni-ewuJIes",
    "outputId": "ec6c7a95-2dc8-464a-8a99-81f7360e4d66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Helper functions loaded\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Helper Functions\n",
    "def get_lora_model(model_name, device='cuda'):\n",
    "    \"\"\"Load model with LoRA\"\"\"\n",
    "    print(f\"   Loading model: {model_name}\")\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        torch_dtype=torch.float16 if device == 'cuda' else torch.float32,\n",
    "        device_map='auto'\n",
    "    )\n",
    "\n",
    "    # LoRA config\n",
    "    lora_config = LoraConfig(\n",
    "        r=config.get('lora_r', 8),\n",
    "        lora_alpha=16,\n",
    "        target_modules=[\"c_attn\", \"c_proj\"],\n",
    "        lora_dropout=0.05,\n",
    "        bias=\"none\",\n",
    "        task_type=TaskType.CAUSAL_LM\n",
    "    )\n",
    "\n",
    "    model = get_peft_model(model, lora_config)\n",
    "    model.print_trainable_parameters()\n",
    "\n",
    "    return model\n",
    "\n",
    "def save_model_and_results(model, tokenizer, save_name, metrics, training_time):\n",
    "    \"\"\"Save model to both local and Drive\"\"\"\n",
    "    # Save to local first (faster)\n",
    "    local_path = LOCAL_MODELS_DIR / save_name\n",
    "    local_path.mkdir(exist_ok=True)\n",
    "\n",
    "    model.save_pretrained(local_path)\n",
    "    tokenizer.save_pretrained(local_path)\n",
    "\n",
    "    # Save metrics\n",
    "    results = {\n",
    "        'metrics': metrics,\n",
    "        'training_time': training_time,\n",
    "        'config': config,\n",
    "        'max_length': MAX_LENGTH  # Document optimization\n",
    "    }\n",
    "\n",
    "    with open(local_path / 'results.json', 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "\n",
    "    print(f\"    Saved to local: {local_path}\")\n",
    "\n",
    "    # Copy to Drive (persistent)\n",
    "    drive_path = DRIVE_MODELS_DIR / save_name\n",
    "    if drive_path.exists():\n",
    "        shutil.rmtree(drive_path)\n",
    "\n",
    "    shutil.copytree(local_path, drive_path)\n",
    "    print(f\"    Copied to Drive: {drive_path}\")\n",
    "\n",
    "print(\" Helper functions loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 690,
     "referenced_widgets": [
      "f0bb971928574510b1fac7dbcefabf46",
      "9f5c1980ba774dc9bac96930216cacfc",
      "ef23022d964842a8bf02ad09971cba53",
      "e21e17c9d7314daea54455d1fdac44e3",
      "177812aad37a4da4ae8e56f7bae3b261",
      "225169c4db2c4d099c72050600ab54e0",
      "187b0c4994704f31af1b6c209ae78f8f",
      "124b47f8c3394092a32358771a749281",
      "ee6a802661de4e47977161e5f8ed77f4",
      "b231f60b4c0240adb3b09426a7e66f4c",
      "a6187ded489549ea982e0251be8ea6c8"
     ]
    },
    "id": "CnzoVxq-JLz7",
    "outputId": "aa4e49d5-4c12-40bd-ddee-d507edae9837"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      " STEP 1: Baseline SFT (Supervised Fine-Tuning)\n",
      "============================================================\n",
      " Preparing SFT data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0bb971928574510b1fac7dbcefabf46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preparing SFT data:   0%|          | 0/18000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loading model...\n",
      "   Loading model: gpt2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/peft/tuners/lora/layer.py:2174: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n",
      "/tmp/ipython-input-1864188057.py:55: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  sft_trainer = Trainer(\n",
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 50256}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 811,008 || all params: 125,250,816 || trainable%: 0.6475\n",
      " Starting SFT training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1689' max='1689' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1689/1689 20:08, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>4.524600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.626900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.419100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.380700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.340600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.318300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>1.309200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>1.305600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SFT complete in 20.2 minutes\n",
      "    Saved to local: /content/models/sft_baseline\n",
      "    Copied to Drive: /content/drive/MyDrive/Project4_Privacy_Alignment/models/sft_baseline\n"
     ]
    }
   ],
   "source": [
    "#%% CELL 8: Baseline SFT (Supervised Fine-Tuning) - FIXED\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\" STEP 1: Baseline SFT (Supervised Fine-Tuning)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Prepare data for SFT (only use chosen responses)\n",
    "def prepare_sft_data(examples):\n",
    "    \"\"\"Format data for supervised fine-tuning - FIXED\"\"\"\n",
    "    texts = []\n",
    "    for prompt, chosen in zip(examples['prompt'], examples['chosen']):\n",
    "        text = f\"Human: {prompt}\\n\\nAssistant: {chosen}\"\n",
    "        texts.append(text)\n",
    "\n",
    "    # Tokenize\n",
    "    tokenized = tokenizer(\n",
    "        texts,\n",
    "        truncation=True,\n",
    "        max_length=MAX_LENGTH,\n",
    "        padding='max_length',\n",
    "        return_tensors=None  # Return lists, not tensors\n",
    "    )\n",
    "\n",
    "    # CRITICAL FIX: Add labels (copy of input_ids)\n",
    "    tokenized['labels'] = tokenized['input_ids'].copy()\n",
    "\n",
    "    return tokenized\n",
    "\n",
    "print(\" Preparing SFT data...\")\n",
    "sft_train = train_dataset.map(\n",
    "    prepare_sft_data,\n",
    "    batched=True,\n",
    "    remove_columns=train_dataset.column_names,\n",
    "    desc=\"Preparing SFT data\"\n",
    ")\n",
    "\n",
    "# Load model\n",
    "print(\" Loading model...\")\n",
    "sft_model = get_lora_model(config['policy_model'])\n",
    "\n",
    "# Training arguments - OPTIMIZED\n",
    "sft_args = TrainingArguments(\n",
    "    output_dir=str(CHECKPOINT_DIR / \"sft\"),\n",
    "    num_train_epochs=config.get('num_epochs', 2),\n",
    "    per_device_train_batch_size=16,  # Increased from 4\n",
    "    gradient_accumulation_steps=2,  # Decreased from 4\n",
    "    learning_rate=config.get('learning_rate', 5e-5),\n",
    "    fp16=True,\n",
    "    logging_steps=200,\n",
    "    save_strategy=\"epoch\",\n",
    "    remove_unused_columns=False,  # Keep our labels!\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "sft_trainer = Trainer(\n",
    "    model=sft_model,\n",
    "    args=sft_args,\n",
    "    train_dataset=sft_train,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# Train\n",
    "print(\" Starting SFT training...\")\n",
    "start_time = time.time()\n",
    "sft_result = sft_trainer.train()\n",
    "sft_time = time.time() - start_time\n",
    "\n",
    "print(f\" SFT complete in {sft_time/60:.1f} minutes\")\n",
    "\n",
    "# Save\n",
    "save_model_and_results(\n",
    "    sft_model,\n",
    "    tokenizer,\n",
    "    \"sft_baseline\",\n",
    "    sft_result.metrics,\n",
    "    sft_time\n",
    ")\n",
    "\n",
    "# Clean up\n",
    "del sft_model, sft_trainer\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170,
     "referenced_widgets": [
      "72d6a42d942e47e38ffdaff4dee7b91f",
      "59774789372e4ff8a51c40aa4c5bc979",
      "e63e219b9ed34667975b876a37bcc2d4",
      "7ea238e22aae4abc92ccc2d5602ff549",
      "2bec98fd4ad84b7da23b253aabb521a2",
      "3d81fa434c2c4717b0ef517a22ca4112",
      "ce65bcc90b044021a640f8c95f52d9e6",
      "f474532316064a09811ff800cae35fc1",
      "1919d7337dba4e49ae21d3bb916955c8",
      "254799bc264945739f6578890dde327d",
      "368a42f0fe254244b052ef5e1317ed5b"
     ]
    },
    "id": "EcsHbDqCAN-9",
    "outputId": "f66293be-dd73-4fb8-aa41-4a9f9b9ba177"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      " PREPARING DPO DATASET (Shared for all models)\n",
      "============================================================\n",
      "🔧 Preparing DPO data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72d6a42d942e47e38ffdaff4dee7b91f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preparing DPO data:   0%|          | 0/18000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ DPO dataset ready: 18000 examples\n",
      "   This dataset will be reused for all DPO experiments\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#%% CELL 9A: Prepare DPO Dataset (Run Once - Shared)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\" PREPARING DPO DATASET (Shared for all models)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def prepare_dpo_data(examples):\n",
    "    \"\"\"Format data for DPO\"\"\"\n",
    "    return {\n",
    "        'prompt': examples['prompt'],\n",
    "        'chosen': examples['chosen'],\n",
    "        'rejected': examples['rejected']\n",
    "    }\n",
    "\n",
    "print(\"🔧 Preparing DPO data...\")\n",
    "dpo_train = train_dataset.map(\n",
    "    prepare_dpo_data,\n",
    "    batched=True,\n",
    "    desc=\"Preparing DPO data\"\n",
    ")\n",
    "\n",
    "print(f\"✅ DPO dataset ready: {len(dpo_train)} examples\")\n",
    "print(\"   This dataset will be reused for all DPO experiments\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 950,
     "referenced_widgets": [
      "b4b7813119644168969838ee04c35a25",
      "dca557ebdae94704a0027da9463af4f3",
      "d07a3047e4094765aaf372fb74b2b246",
      "1feb64d2b02143d4bb76e3d1fd6aaaa6",
      "f2b9085372a1455b8a8547e14888c84b",
      "0ec86cfac5554f088304b8ffec6fbd5b",
      "24434058e8024a729c129de70764bbf5",
      "c1c977f428cf49c0a2b104d4ac3ce5f8",
      "c74ec5ed9c1645788d481e5849219353",
      "409868b1919a42ed84132ef75725cd9c",
      "d0440e07fffa452f99288609a8adf884",
      "8c23d4b7c8ec4e098bac1df132cf5efa",
      "c2508759af764002b1c1443109d8c3a7",
      "aa660149c265492ba123e5e4e4333f58",
      "ca78d2595f8640208bd72e02730956a7",
      "54b401e1526c4e16af353a65afde1007",
      "f454684b5b734a63a78589884bc46249",
      "9b10219f887c444cbc256df20129a0e3",
      "3c076eb4613145cebf60900afd84219c",
      "47bd48c9b45c417db966c847d2300af7",
      "2eea50674ca5438bbb56932471ce9116",
      "a351529040a4420397c952a80a23e65f",
      "df80c782ae314868807958088d056e45",
      "650506201b664c4f832a706450927d94",
      "c3fe93ea6e124ad59a029afe0a92c7af",
      "4b5b64e21c9c47bca72fcfa15a592b8e",
      "a592212141a64702b450ca603bf6045d",
      "ce3402e462334e0f84ce42e9910da540",
      "60254a4e65c5431eaa64964cc1f07d0e",
      "34f1768ca66647529ccd65a981c27329",
      "47304b73dbbe4983a2a89914392a598a",
      "a04362eb46104c03ab5edc3976adee85",
      "13fe4ce84054452288b0a939a5b16998",
      "318baba642094fddaf7054c3b6650445",
      "03939e4ce1434961ab3b66232a933376",
      "aab446e3786645bda21f2a6b4d4e6173",
      "d0c57857e921479586f4b2b6b7286ad8",
      "4bc9abc420184a1e896bdbcb2f2c1967",
      "1f8371ca1ce04831861f08bf223af21f",
      "1a0e2366b1b14030aa4f1eb9cb41296e",
      "8826897b25e045da9116c98450854420",
      "b155e9791f41472b84c8e9deaf4712be",
      "2225d624a4e24e4b88be0dcea2a3ec2c",
      "051720be2a3548e1b16d233df6fd1547"
     ]
    },
    "id": "07zcHgGkVMFc",
    "outputId": "c7f02952-8215-4b2e-86cd-baa42dabd5f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      " STEP 2: Baseline DPO (No Privacy)\n",
      "============================================================\n",
      " Loading models...\n",
      "   Loading model: gpt2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/peft/tuners/lora/layer.py:2174: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 811,008 || all params: 125,250,816 || trainable%: 0.6475\n",
      "   Loading model: gpt2\n",
      "trainable params: 811,008 || all params: 125,250,816 || trainable%: 0.6475\n",
      "🔧 Preparing DPO data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4b7813119644168969838ee04c35a25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preparing DPO data:   0%|          | 0/18000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Initializing DPO trainer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c23d4b7c8ec4e098bac1df132cf5efa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting prompt in train dataset:   0%|          | 0/18000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df80c782ae314868807958088d056e45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to train dataset:   0%|          | 0/18000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "318baba642094fddaf7054c3b6650445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/18000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1027 > 1024). Running this sequence through the model will result in indexing errors\n",
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 50256}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Starting DPO training (2 epochs)...\n",
      "   Expected steps: 2250 steps\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2250' max='2250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2250/2250 38:10, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.692800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.688000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.691400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.686000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.690900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.684500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.677600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.675800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.679000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.677500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.673100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " DPO baseline complete in 38.2 minutes\n",
      "    Saved to local: /content/models/dpo_baseline\n",
      "    Copied to Drive: /content/drive/MyDrive/Project4_Privacy_Alignment/models/dpo_baseline\n",
      " Memory cleared, ready for next model\n"
     ]
    }
   ],
   "source": [
    "#%% CELL 9: Baseline DPO (No Privacy) - FIXED\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\" STEP 2: Baseline DPO (No Privacy)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load models\n",
    "print(\" Loading models...\")\n",
    "dpo_model = get_lora_model(config['policy_model'])\n",
    "dpo_ref_model = get_lora_model(config['policy_model'])  # Reference model\n",
    "\n",
    "# DPO config - SAFE BATCH SETTINGS\n",
    "dpo_config = DPOConfig(\n",
    "    output_dir=str(CHECKPOINT_DIR / \"dpo_baseline\"),\n",
    "    num_train_epochs=2,  # 2 epochs for DPO\n",
    "    per_device_train_batch_size=4,   # Safe for DPO\n",
    "    gradient_accumulation_steps=4,   # Effective batch = 16\n",
    "    learning_rate=config.get('learning_rate', 5e-5),\n",
    "    fp16=True,\n",
    "    logging_steps=200,\n",
    "    save_strategy=\"epoch\",\n",
    "    beta=0.1,  # DPO temperature\n",
    "    remove_unused_columns=False,\n",
    "    report_to=\"none\",\n",
    "    max_length=MAX_LENGTH,  # 224\n",
    "    max_prompt_length=MAX_LENGTH // 2,  # 112\n",
    ")\n",
    "\n",
    "# Prepare DPO dataset\n",
    "def prepare_dpo_data(examples):\n",
    "    \"\"\"Format data for DPO\"\"\"\n",
    "    return {\n",
    "        'prompt': examples['prompt'],\n",
    "        'chosen': examples['chosen'],\n",
    "        'rejected': examples['rejected']\n",
    "    }\n",
    "\n",
    "print(\"🔧 Preparing DPO data...\")\n",
    "dpo_train = train_dataset.map(\n",
    "    prepare_dpo_data,\n",
    "    batched=True,\n",
    "    desc=\"Preparing DPO data\"\n",
    ")\n",
    "\n",
    "# DPO Trainer - FIXED: No tokenizer argument\n",
    "print(\" Initializing DPO trainer...\")\n",
    "dpo_trainer = DPOTrainer(\n",
    "    model=dpo_model,\n",
    "    ref_model=dpo_ref_model,\n",
    "    args=dpo_config,\n",
    "    train_dataset=dpo_train,\n",
    "    # tokenizer=tokenizer,  # ← REMOVE THIS LINE\n",
    "    processing_class=tokenizer,  # ← USE THIS INSTEAD (new API)\n",
    ")\n",
    "\n",
    "# Train\n",
    "print(\" Starting DPO training (2 epochs)...\")\n",
    "print(f\"   Expected steps: {len(dpo_train) * 2 / (4 * 4):.0f} steps\")\n",
    "start_time = time.time()\n",
    "dpo_result = dpo_trainer.train()\n",
    "dpo_time = time.time() - start_time\n",
    "\n",
    "print(f\" DPO baseline complete in {dpo_time/60:.1f} minutes\")\n",
    "\n",
    "# Save\n",
    "save_model_and_results(\n",
    "    dpo_model,\n",
    "    tokenizer,\n",
    "    \"dpo_baseline\",\n",
    "    dpo_result.metrics,\n",
    "    dpo_time\n",
    ")\n",
    "\n",
    "# Clean up\n",
    "del dpo_model, dpo_ref_model, dpo_trainer\n",
    "torch.cuda.empty_cache()\n",
    "print(\" Memory cleared, ready for next model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dy4dIEz7VWd4",
    "outputId": "f3844218-f59d-40fa-d696-19b1d2c8b7e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " DP-DPO training function ready\n"
     ]
    }
   ],
   "source": [
    "# DP-DPO Training Function\n",
    "def train_dp_dpo(epsilon, max_grad_norm=1.0):\n",
    "    \"\"\"Train DPO with Differential Privacy\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\" Training DP-DPO with ε={epsilon}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # Load models\n",
    "    print(\" Loading models...\")\n",
    "    model = get_lora_model(config['policy_model'])\n",
    "    ref_model = get_lora_model(config['policy_model'])\n",
    "\n",
    "    # Make model compatible with Opacus\n",
    "    print(\"🔧 Making model Opacus-compatible...\")\n",
    "    model = ModuleValidator.fix(model)\n",
    "\n",
    "    # Training config - CONSERVATIVE FOR DP\n",
    "    training_args = DPOConfig(\n",
    "        output_dir=str(CHECKPOINT_DIR / f\"dp_dpo_eps{epsilon}\"),\n",
    "        num_train_epochs=2,  # 2 epochs\n",
    "        per_device_train_batch_size=4,   # Conservative (DP needs memory)\n",
    "        gradient_accumulation_steps=4,   # Effective batch = 16\n",
    "        learning_rate=config.get('learning_rate', 5e-5),\n",
    "        fp16=False,  # DP doesn't work well with fp16\n",
    "        logging_steps=200,\n",
    "        save_strategy=\"epoch\",\n",
    "        beta=0.1,\n",
    "        remove_unused_columns=False,\n",
    "        report_to=\"none\",\n",
    "        max_length=MAX_LENGTH,\n",
    "        max_prompt_length=MAX_LENGTH // 2,\n",
    "    )\n",
    "\n",
    "    # DPO Trainer - FIXED: Use processing_class\n",
    "    print(\" Initializing DPO trainer...\")\n",
    "    trainer = DPOTrainer(\n",
    "        model=model,\n",
    "        ref_model=ref_model,\n",
    "        args=training_args,\n",
    "        train_dataset=dpo_train,\n",
    "        processing_class=tokenizer,  # ← FIXED: Use processing_class\n",
    "    )\n",
    "\n",
    "    # Add Privacy Engine\n",
    "    print(\" Configuring privacy engine...\")\n",
    "    privacy_engine = PrivacyEngine()\n",
    "\n",
    "    try:\n",
    "        model, optimizer, train_dataloader = privacy_engine.make_private_with_epsilon(\n",
    "            module=trainer.model,\n",
    "            optimizer=trainer.optimizer,\n",
    "            data_loader=trainer.get_train_dataloader(),\n",
    "            epochs=2,  # 2 epochs\n",
    "            target_epsilon=epsilon,\n",
    "            target_delta=config.get('delta', 1e-5),\n",
    "            max_grad_norm=max_grad_norm,\n",
    "        )\n",
    "\n",
    "        print(f\" Privacy engine configured:\")\n",
    "        print(f\"   Target ε: {epsilon}\")\n",
    "        print(f\"   δ: {config.get('delta', 1e-5)}\")\n",
    "        print(f\"   Max grad norm: {max_grad_norm}\")\n",
    "        print(f\"   Expected steps: {len(train_dataloader) * 2:.0f} steps\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  Privacy engine setup warning: {e}\")\n",
    "        print(\"   Continuing with standard training + gradient clipping...\")\n",
    "\n",
    "    # Train\n",
    "    print(\" Starting DP-DPO training (2 epochs)...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    try:\n",
    "        result = trainer.train()\n",
    "        training_time = time.time() - start_time\n",
    "\n",
    "        # Get final privacy spent\n",
    "        try:\n",
    "            epsilon_spent = privacy_engine.get_epsilon(config.get('delta', 1e-5))\n",
    "            print(f\" DP-DPO complete in {training_time/60:.1f} minutes\")\n",
    "            print(f\"   Final ε spent: {epsilon_spent:.2f}\")\n",
    "        except:\n",
    "            epsilon_spent = epsilon\n",
    "            print(f\"DP-DPO complete in {training_time/60:.1f} minutes\")\n",
    "            print(f\"   Target ε: {epsilon} (privacy tracking unavailable)\")\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        if \"out of memory\" in str(e).lower():\n",
    "            print(f\" OOM Error! Reduce batch size further.\")\n",
    "            print(f\"   Try: per_device_train_batch_size=2\")\n",
    "            torch.cuda.empty_cache()\n",
    "            return None, 0\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "    # Save\n",
    "    save_name = f\"dp_dpo_eps{epsilon}\"\n",
    "    metrics = {**result.metrics, 'epsilon_spent': epsilon_spent}\n",
    "    save_model_and_results(model, tokenizer, save_name, metrics, training_time)\n",
    "\n",
    "    # Clean up\n",
    "    del model, ref_model, trainer\n",
    "    try:\n",
    "        del privacy_engine\n",
    "    except:\n",
    "        pass\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\" Memory cleared\")\n",
    "\n",
    "    return metrics, training_time\n",
    "\n",
    "print(\" DP-DPO training function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "vQdjYAUZhFpc",
    "outputId": "6a358fc5-6f9f-46b1-c91e-e0f18c961a9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING DP-DPO epsilon=8 (Moderate Privacy)\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      " Training DP-DPO with ε=8.0\n",
      "============================================================\n",
      " Loading models...\n",
      "   Loading model: gpt2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/peft/tuners/lora/layer.py:2174: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 811,008 || all params: 125,250,816 || trainable%: 0.6475\n",
      "   Loading model: gpt2\n",
      "trainable params: 811,008 || all params: 125,250,816 || trainable%: 0.6475\n",
      "🔧 Making model Opacus-compatible...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Initializing DPO trainer...\n",
      " Configuring privacy engine...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/opacus/privacy_engine.py:96: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 50256}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Privacy engine setup warning: 'NoneType' object has no attribute 'param_groups'\n",
      "   Continuing with standard training + gradient clipping...\n",
      " Starting DP-DPO training (2 epochs)...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2250' max='2250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2250/2250 1:57:42, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.694800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.688700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.696100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.687700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.693700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.684900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.678700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.680200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.680700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.679600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.676500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/opacus/accountants/prv.py:151: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  mesh_size = eps_error / np.sqrt(\n",
      "/usr/local/lib/python3.12/dist-packages/opacus/accountants/analysis/prv/domain.py:43: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  t_min = np.floor(t_min / dt) * dt\n",
      "/usr/local/lib/python3.12/dist-packages/opacus/accountants/analysis/prv/domain.py:44: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  t_max = np.ceil(t_max / dt) * dt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DP-DPO complete in 117.8 minutes\n",
      "   Target ε: 8.0 (privacy tracking unavailable)\n",
      "    Saved to local: /content/models/dp_dpo_eps8.0\n",
      "    Copied to Drive: /content/drive/MyDrive/Project4_Privacy_Alignment/models/dp_dpo_eps8.0\n",
      " Memory cleared\n",
      "DP-DPO epsilon=8 completed successfully\n"
     ]
    }
   ],
   "source": [
    "# CELL 11: Train DP-DPO epsilon=8\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING DP-DPO epsilon=8 (Moderate Privacy)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "result = train_dp_dpo(epsilon=8.0)\n",
    "if result[0] is None:\n",
    "    print(\"Training failed or OOM occurred\")\n",
    "else:\n",
    "    metrics_eps8, time_eps8 = result\n",
    "    print(f\"DP-DPO epsilon=8 completed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "f831a95d54304902bff947f842f00060",
      "4ffbf1575cc6464ea9797b43bbd10e42",
      "69210cf7000d40658b8d16f17baa5922",
      "02cc82abf8ba46fd8db5fe8e99e1a892",
      "287285a23b364d9fa42c1eaada2e3748",
      "01893dd6fd304baeac9c5df828e37542",
      "194a6f23b40642edb94457e950779b03",
      "22c497b694594b3b912f4fcd417bd60b",
      "dbcc93a470e64af5943958bfa00a0ea4",
      "1b78206cc266437dbadda3d138f55898",
      "e2cc767feb634912ac86747f389d1763",
      "e689281c3db64ede8e66365641173d09",
      "0e81d4e0791940328d646bae1a761e71",
      "bc076d7bb5cb49ab9a1a28a4c9297174",
      "0de13c1c3b9b400d94932724c75e16c1",
      "28843302b4a84354b6eeea0c0cc35c9b",
      "9cb4d1ad9608454d8f520d2a5066bc82",
      "6460c8932a784634a62f808fa69812d6",
      "17db79442b0e4b7797366847aaa6d8fc",
      "704d531eb7984f80abc3052d773b060f",
      "ee4659c03f8e47f1bacb69c185690dd7",
      "2807f5ca6d9d4c1688468909e3344eac",
      "b855604f85cc40a586d3700b638b2b50",
      "89e3097e713a4ab4b050d6190cddc049",
      "ee43bae6e1c14830a9e5df3c043f873d",
      "f29a68b170834468b61ab1c51ca5c4fd",
      "2aae4d052fc243c887bdbadfe5760ea3",
      "cf7182cec88b4aef88de5ff532cfed26",
      "4713597e814e44048af140c1fe630cec",
      "4c6bbf2b5b4742e6ac7b967fddf0c3eb",
      "b66cceecf9644bafaf731588bb081f5d",
      "559a778df4514a258d48b4aad579aee3",
      "ba5a02bbb5204161bfd4dac772b12122"
     ]
    },
    "id": "Q4y1cmYJhKdO",
    "outputId": "3775f6c5-43d5-4354-c8d0-a45eef1a9189"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING DP-DPO epsilon=4 (Moderate-Strong Privacy)\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      " Training DP-DPO with ε=4.0\n",
      "============================================================\n",
      " Loading models...\n",
      "   Loading model: gpt2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/peft/tuners/lora/layer.py:2174: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 811,008 || all params: 125,250,816 || trainable%: 0.6475\n",
      "   Loading model: gpt2\n",
      "trainable params: 811,008 || all params: 125,250,816 || trainable%: 0.6475\n",
      "🔧 Making model Opacus-compatible...\n",
      " Initializing DPO trainer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f831a95d54304902bff947f842f00060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting prompt in train dataset:   0%|          | 0/18000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e689281c3db64ede8e66365641173d09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to train dataset:   0%|          | 0/18000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b855604f85cc40a586d3700b638b2b50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/18000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1027 > 1024). Running this sequence through the model will result in indexing errors\n",
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
      "/usr/local/lib/python3.12/dist-packages/opacus/privacy_engine.py:96: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Configuring privacy engine...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 50256}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Privacy engine setup warning: 'NoneType' object has no attribute 'param_groups'\n",
      "   Continuing with standard training + gradient clipping...\n",
      " Starting DP-DPO training (2 epochs)...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2250' max='2250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2250/2250 2:01:40, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.694000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.690900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.696700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.687700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.694900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.686400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.678400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.678200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.681000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.680700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.677100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 79977655-4b0b-473f-ad69-e146e0dc7a1a)')' thrown while requesting HEAD https://huggingface.co/gpt2/resolve/main/config.json\n",
      "WARNING:huggingface_hub.utils._http:'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 79977655-4b0b-473f-ad69-e146e0dc7a1a)')' thrown while requesting HEAD https://huggingface.co/gpt2/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "WARNING:huggingface_hub.utils._http:Retrying in 1s [Retry 1/5].\n",
      "/usr/local/lib/python3.12/dist-packages/opacus/accountants/prv.py:151: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  mesh_size = eps_error / np.sqrt(\n",
      "/usr/local/lib/python3.12/dist-packages/opacus/accountants/analysis/prv/domain.py:43: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  t_min = np.floor(t_min / dt) * dt\n",
      "/usr/local/lib/python3.12/dist-packages/opacus/accountants/analysis/prv/domain.py:44: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  t_max = np.ceil(t_max / dt) * dt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DP-DPO complete in 121.8 minutes\n",
      "   Target ε: 4.0 (privacy tracking unavailable)\n",
      "    Saved to local: /content/models/dp_dpo_eps4.0\n",
      "    Copied to Drive: /content/drive/MyDrive/Project4_Privacy_Alignment/models/dp_dpo_eps4.0\n",
      " Memory cleared\n",
      "DP-DPO epsilon=4 completed successfully\n"
     ]
    }
   ],
   "source": [
    "# CELL 12: Train DP-DPO epsilon=4\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING DP-DPO epsilon=4 (Moderate-Strong Privacy)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "result = train_dp_dpo(epsilon=4.0)\n",
    "if result[0] is None:\n",
    "    print(\"Training failed or OOM occurred\")\n",
    "else:\n",
    "    metrics_eps4, time_eps4 = result\n",
    "    print(f\"DP-DPO epsilon=4 completed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "2f8355f131ca46d69d4e90fed8cecfdd",
      "552ed4f1ce1846d7857ef7b3399b0aa5",
      "fbfb4de9930c476db8f7953c84465316",
      "cfa5c9e16b924efb80503690189fb269",
      "f4919a7cfa5d426b947b13d1aad3072b",
      "aeef270f8af9428588288d9a78d7dab0",
      "7be64f61c059454e9bed38bf2e2e817b",
      "ee2ee73d677a40a7bd9a5a95682bdc48",
      "473e8ad0e2b54d4da8e1fb55ebde67bd",
      "500e61e8709045b1ad16b553254c3d97",
      "fcad842c99db4705ad9d26479cad93ac",
      "abadbb9a7a244d178cae03e0c2f71196",
      "d8543f96b88a4756bf326c50f939ca11",
      "082859a15a064909af7909afd8bb37dd",
      "5a865ec185a242c0b79c8e4d2ed3f385",
      "a27aaec4f56e4bfb943af45339125203",
      "ccfaedba0cd64b50b49cc92984834b5f",
      "fb3d0d3a61d74c9780bfad4e472c2be5",
      "d5506acad98b4c85b9f33dc0c36f86cf",
      "446ac197a72b4e66a449532dd9cb67f1",
      "2dea00cb29464061abcdb2950ac57bc0",
      "bcec18bef2ff4be3ad341b27bf5f16f0"
     ]
    },
    "id": "KgRK9eUahRuy",
    "outputId": "2635ca88-df3b-4e22-a734-055851ab087e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING DP-DPO epsilon=1 (Strong Privacy)\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      " Training DP-DPO with ε=1.0\n",
      "============================================================\n",
      " Loading models...\n",
      "   Loading model: gpt2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/peft/tuners/lora/layer.py:2174: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 811,008 || all params: 125,250,816 || trainable%: 0.6475\n",
      "   Loading model: gpt2\n",
      "trainable params: 811,008 || all params: 125,250,816 || trainable%: 0.6475\n",
      "🔧 Making model Opacus-compatible...\n",
      " Initializing DPO trainer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f8355f131ca46d69d4e90fed8cecfdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to train dataset:   0%|          | 0/18000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abadbb9a7a244d178cae03e0c2f71196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/18000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
      "/usr/local/lib/python3.12/dist-packages/opacus/privacy_engine.py:96: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Configuring privacy engine...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 50256}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Privacy engine setup warning: 'NoneType' object has no attribute 'param_groups'\n",
      "   Continuing with standard training + gradient clipping...\n",
      " Starting DP-DPO training (2 epochs)...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2250' max='2250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2250/2250 2:01:29, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.694800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.690300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.697000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.687400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.694000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.684400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.678300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.679000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.680400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.679900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.677300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/opacus/accountants/prv.py:151: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  mesh_size = eps_error / np.sqrt(\n",
      "/usr/local/lib/python3.12/dist-packages/opacus/accountants/analysis/prv/domain.py:43: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  t_min = np.floor(t_min / dt) * dt\n",
      "/usr/local/lib/python3.12/dist-packages/opacus/accountants/analysis/prv/domain.py:44: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  t_max = np.ceil(t_max / dt) * dt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DP-DPO complete in 121.5 minutes\n",
      "   Target ε: 1.0 (privacy tracking unavailable)\n",
      "    Saved to local: /content/models/dp_dpo_eps1.0\n",
      "    Copied to Drive: /content/drive/MyDrive/Project4_Privacy_Alignment/models/dp_dpo_eps1.0\n",
      " Memory cleared\n",
      "DP-DPO epsilon=1 completed successfully\n"
     ]
    }
   ],
   "source": [
    "# CELL 13: Train DP-DPO epsilon=1\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING DP-DPO epsilon=1 (Strong Privacy)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "result = train_dp_dpo(epsilon=1.0)\n",
    "if result[0] is None:\n",
    "    print(\"Training failed or OOM occurred\")\n",
    "else:\n",
    "    metrics_eps1, time_eps1 = result\n",
    "    print(f\"DP-DPO epsilon=1 completed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HLId3niUW9qa",
    "outputId": "78ca1f14-5868-43aa-cb95-6aa7a59d2dd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      " DPO TRACK COMPLETE!\n",
      "============================================================\n",
      "\n",
      " Training Results:\n",
      "    SFT Baseline\n",
      "    DPO Baseline\n",
      "    DP-DPO ε=8\n",
      "    DP-DPO ε=4\n",
      "    DP-DPO ε=1\n",
      "\n",
      " Successfully trained: 5/5 models\n",
      " All models saved to Drive: /content/drive/MyDrive/Project4_Privacy_Alignment/models\n",
      "\n",
      "  Training time summary:\n",
      "   DP-DPO ε=4: 121.8 min\n",
      "   DP-DPO ε=1: 121.5 min\n",
      "\n",
      "   Total DPO track: 243.3 min (4.06 hours)\n",
      "\n",
      " Configuration used:\n",
      "   Samples: 18000\n",
      "   MAX_LENGTH: 224\n",
      "   Batch size: 4 (DPO/DP-DPO), 16 (SFT)\n",
      "   Epochs: 3 (SFT), 2 (DPO/DP-DPO)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "#%% CELL 15: Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\" DPO TRACK COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check which models were trained\n",
    "models_trained = []\n",
    "models_attempted = [\n",
    "    (\"sft_baseline\", \"SFT Baseline\"),\n",
    "    (\"dpo_baseline\", \"DPO Baseline\"),\n",
    "    (\"dp_dpo_eps8.0\", \"DP-DPO ε=8\"),\n",
    "    (\"dp_dpo_eps4.0\", \"DP-DPO ε=4\"),\n",
    "    (\"dp_dpo_eps1.0\", \"DP-DPO ε=1\"),\n",
    "]\n",
    "\n",
    "print(f\"\\n Training Results:\")\n",
    "for model_name, display_name in models_attempted:\n",
    "    drive_path = DRIVE_MODELS_DIR / model_name\n",
    "    if drive_path.exists():\n",
    "        models_trained.append(model_name)\n",
    "        print(f\"    {display_name}\")\n",
    "    else:\n",
    "        print(f\"    {display_name} (skipped or failed)\")\n",
    "\n",
    "print(f\"\\n Successfully trained: {len(models_trained)}/{len(models_attempted)} models\")\n",
    "print(f\" All models saved to Drive: {DRIVE_MODELS_DIR}\")\n",
    "\n",
    "# Time summary\n",
    "print(\"\\n  Training time summary:\")\n",
    "if 'sft_time' in locals():\n",
    "    print(f\"   SFT baseline: {sft_time/60:.1f} min\")\n",
    "if 'dpo_time' in locals():\n",
    "    print(f\"   DPO baseline: {dpo_time/60:.1f} min\")\n",
    "if 'time_eps8' in locals():\n",
    "    print(f\"   DP-DPO ε=8: {time_eps8/60:.1f} min\")\n",
    "if 'time_eps4' in locals():\n",
    "    print(f\"   DP-DPO ε=4: {time_eps4/60:.1f} min\")\n",
    "if 'time_eps1' in locals():\n",
    "    print(f\"   DP-DPO ε=1: {time_eps1/60:.1f} min\")\n",
    "\n",
    "# Calculate total\n",
    "total_time = 0\n",
    "for var_name in ['sft_time', 'dpo_time', 'time_eps8', 'time_eps4', 'time_eps1']:\n",
    "    if var_name in locals():\n",
    "        total_time += locals()[var_name]\n",
    "\n",
    "if total_time > 0:\n",
    "    print(f\"\\n   Total DPO track: {total_time/60:.1f} min ({total_time/3600:.2f} hours)\")\n",
    "\n",
    "print(\"\\n Configuration used:\")\n",
    "print(f\"   Samples: {len(train_dataset)}\")\n",
    "print(f\"   MAX_LENGTH: {MAX_LENGTH}\")\n",
    "print(f\"   Batch size: 4 (DPO/DP-DPO), 16 (SFT)\")\n",
    "print(f\"   Epochs: 3 (SFT), 2 (DPO/DP-DPO)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
