{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f71D_2t9qoN3"
   },
   "source": [
    "\"\"\"\n",
    "═══════════════════════════════════════════════════════════════════════════\n",
    "NOTEBOOK 1: Multi-Task LoRA Experts Training\n",
    "═══════════════════════════════════════════════════════════════════════════\n",
    "Train 4 specialized LoRA adapters for different tasks\n",
    "Model: TinyLlama-1.1B-Chat-v1.0 (1.1B parameters)\n",
    "Tasks: Medical, Code, Math, Creative Writing\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mbZli7n_qpl7",
    "outputId": "f083bb93-0e5a-412a-8735-f3317dace49e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h PyTorch version: 2.8.0+cu126\n",
      " CUDA available: True\n",
      " GPU: Tesla T4\n",
      " GPU Memory: 15.83 GB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# CELL 1: Setup & Installation\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "!pip install -q transformers datasets peft accelerate bitsandbytes sentencepiece torch\n",
    "\n",
    "# Verify GPU\n",
    "import torch\n",
    "print(f\" PyTorch version: {torch.__version__}\")\n",
    "print(f\" CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\" GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\" GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oq8tIqF0qpoy",
    "outputId": "00a7fa02-ec97-4006-df98-848d0cefc1e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# CELL 2: Import Libraries\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    TaskType\n",
    ")\n",
    "from datasets import load_dataset\n",
    "import json\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, List, Dict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\" All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N2jecRlFqprm"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# CELL 3: Configuration\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "@dataclass\n",
    "class TaskConfig:\n",
    "    \"\"\"Configuration for each task\"\"\"\n",
    "    name: str\n",
    "    dataset_name: str\n",
    "    dataset_config: Optional[str]\n",
    "    prompt_template: str\n",
    "    lora_r: int = 16\n",
    "    lora_alpha: int = 32\n",
    "    lora_dropout: float = 0.1\n",
    "    num_samples: int = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nqinFaF6qpuV",
    "outputId": "f883f26f-71b5-4915-ca7a-a1061b876fda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Configuration loaded\n",
      "  Model: TinyLlama/TinyLlama-1.1B-Chat-v1.0\n",
      "  Tasks: ['medical', 'code', 'math', 'creative']\n",
      "  Max Length: 512\n",
      "  Batch Size: 4\n",
      "  Learning Rate: 0.0002\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define 4 specialized tasks\n",
    "TASKS = {\n",
    "    \"medical\": TaskConfig(\n",
    "        name=\"medical_conversation\",\n",
    "        dataset_name=\"medalpaca/medical_meadow_medical_flashcards\",\n",
    "        dataset_config=None,\n",
    "        prompt_template=\"### Medical Question:\\n{input}\\n\\n### Answer:\\n{output}\",\n",
    "        lora_r=16,\n",
    "        lora_alpha=32,\n",
    "        num_samples=5000\n",
    "    ),\n",
    "    \"code\": TaskConfig(\n",
    "        name=\"code_generation\",\n",
    "        dataset_name=\"iamtarun/python_code_instructions_18k_alpaca\",\n",
    "        dataset_config=None,\n",
    "        prompt_template=\"### Instruction:\\n{input}\\n\\n### Code:\\n{output}\",\n",
    "        lora_r=16,\n",
    "        lora_alpha=32,\n",
    "        num_samples=5000\n",
    "    ),\n",
    "    \"math\": TaskConfig(\n",
    "        name=\"math_reasoning\",\n",
    "        dataset_name=\"gsm8k\",\n",
    "        dataset_config=\"main\",\n",
    "        prompt_template=\"### Problem:\\n{input}\\n\\n### Solution:\\n{output}\",\n",
    "        lora_r=16,\n",
    "        lora_alpha=32,\n",
    "        num_samples=5000\n",
    "    ),\n",
    "    \"creative\": TaskConfig(\n",
    "        name=\"creative_writing\",\n",
    "        dataset_name=\"euclaise/writingprompts\",\n",
    "        dataset_config=None,\n",
    "        prompt_template=\"### Writing Prompt:\\n{input}\\n\\n### Story:\\n{output}\",\n",
    "        lora_r=16,\n",
    "        lora_alpha=32,\n",
    "        num_samples=3000  # Smaller for creative to avoid very long texts\n",
    "    )\n",
    "}\n",
    "\n",
    "# Model and training configuration\n",
    "MODEL_NAME = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "MAX_LENGTH = 512\n",
    "BATCH_SIZE = 4\n",
    "GRADIENT_ACCUMULATION_STEPS = 4\n",
    "LEARNING_RATE = 2e-4\n",
    "NUM_EPOCHS = 3\n",
    "WARMUP_STEPS = 100\n",
    "\n",
    "print(\" Configuration loaded\")\n",
    "print(f\"  Model: {MODEL_NAME}\")\n",
    "print(f\"  Tasks: {list(TASKS.keys())}\")\n",
    "print(f\"  Max Length: {MAX_LENGTH}\")\n",
    "print(f\"  Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"  Learning Rate: {LEARNING_RATE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zsis2w0jqy_c",
    "outputId": "3250bc66-2329-4846-b66f-3c10967cd4cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dataset class defined\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# CELL 4: Dataset Class\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "class TaskDataset(Dataset):\n",
    "    \"\"\"Dataset for a specific task\"\"\"\n",
    "    def __init__(self, data: List[Dict], tokenizer, max_length: int = 512):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        text = item['text']\n",
    "\n",
    "        # Tokenize\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
    "            'labels': encoding['input_ids'].squeeze()\n",
    "        }\n",
    "\n",
    "print(\" Dataset class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fUr6T8gdqpxK",
    "outputId": "e49faf2e-ce84-431b-d157-301523ad0a4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Data preparation functions defined\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# CELL 5: Data Preparation Functions\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "def prepare_medical_data(dataset, config: TaskConfig):\n",
    "    \"\"\"Prepare medical conversation data\"\"\"\n",
    "    print(f\"  Preparing medical data (target: {config.num_samples} samples)...\")\n",
    "    data = []\n",
    "    for i, item in enumerate(dataset):\n",
    "        if len(data) >= config.num_samples:\n",
    "            break\n",
    "\n",
    "        input_text = item.get('input', '') or item.get('instruction', '')\n",
    "        output_text = item.get('output', '') or item.get('response', '')\n",
    "\n",
    "        if input_text and output_text:\n",
    "            text = config.prompt_template.format(input=input_text, output=output_text)\n",
    "            data.append({'text': text})\n",
    "\n",
    "    print(f\"   Prepared {len(data)} medical samples\")\n",
    "    return data\n",
    "\n",
    "def prepare_code_data(dataset, config: TaskConfig):\n",
    "    \"\"\"Prepare code generation data\"\"\"\n",
    "    print(f\"  Preparing code data (target: {config.num_samples} samples)...\")\n",
    "    data = []\n",
    "    for i, item in enumerate(dataset):\n",
    "        if len(data) >= config.num_samples:\n",
    "            break\n",
    "\n",
    "        input_text = item.get('instruction', '')\n",
    "        output_text = item.get('output', '')\n",
    "\n",
    "        if input_text and output_text:\n",
    "            text = config.prompt_template.format(input=input_text, output=output_text)\n",
    "            data.append({'text': text})\n",
    "\n",
    "    print(f\"   Prepared {len(data)} code samples\")\n",
    "    return data\n",
    "\n",
    "def prepare_math_data(dataset, config: TaskConfig):\n",
    "    \"\"\"Prepare math reasoning data\"\"\"\n",
    "    print(f\"  Preparing math data (target: {config.num_samples} samples)...\")\n",
    "    data = []\n",
    "    for i, item in enumerate(dataset):\n",
    "        if len(data) >= config.num_samples:\n",
    "            break\n",
    "\n",
    "        question = item.get('question', '')\n",
    "        answer = item.get('answer', '')\n",
    "\n",
    "        if question and answer:\n",
    "            text = config.prompt_template.format(input=question, output=answer)\n",
    "            data.append({'text': text})\n",
    "\n",
    "    print(f\"   Prepared {len(data)} math samples\")\n",
    "    return data\n",
    "\n",
    "def prepare_creative_data(dataset, config: TaskConfig):\n",
    "    \"\"\"Prepare creative writing data\"\"\"\n",
    "    print(f\"  Preparing creative data (target: {config.num_samples} samples)...\")\n",
    "    data = []\n",
    "    for i, item in enumerate(dataset):\n",
    "        if len(data) >= config.num_samples:\n",
    "            break\n",
    "\n",
    "        prompt = item.get('prompt', '')\n",
    "        story = item.get('story', '') or item.get('text', '')\n",
    "\n",
    "        if prompt and story and len(story) > 100:\n",
    "            # Truncate very long stories\n",
    "            story = story[:1000]\n",
    "            text = config.prompt_template.format(input=prompt, output=story)\n",
    "            data.append({'text': text})\n",
    "\n",
    "    print(f\"   Prepared {len(data)} creative samples\")\n",
    "    return data\n",
    "\n",
    "print(\" Data preparation functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 249,
     "referenced_widgets": [
      "1da899c00b7a4885ba41217496c3666f",
      "c0297da5ee894cc199248138cdd47519",
      "426f139cde214b8e972711ce70a29a1e",
      "083724bc6dec4833a5a53b62abca27cb",
      "33e4febbb5754602bc864588d839ab41",
      "6cdbd30e3dc143f58d32f07bf9b0e708",
      "d4487797f64d4193a85f61b1bdd93808",
      "46ce809ca00e42b7a90c62f6c696ec7f",
      "e825c5099cdb49dfbbe00de6864ede54",
      "19106227c0ab44db983b13141a5e3204",
      "2c75caaddae244249d93d605af3b82a5",
      "4028636a403f4cc6a8d704013912de5a",
      "4faab0c3c1b54dadab179946610d6a31",
      "6277da7017c2475586cbdca0d9e6d844",
      "ced192cee8b4408c9bea98d641f3a848",
      "bc462041c3314ca2afb60bc93f2806c6",
      "d20b8e3c7c2f4d57ba84eb8dd03356d2",
      "1ed8accfe581471ebb997d0456f80a14",
      "ffdd277ff03e448784bd4cf372c2f451",
      "6c49f204e51e4c378116d30c4b56a2b8",
      "eceeff9a93ce4067a3665c6ab1157904",
      "e1122a1808bb4c679a0398ab37b415aa",
      "2d0e4be80d2f4093874521743eb0a9f6",
      "a1dd02c06d604ae6bc380d791a1e63b3",
      "21dacd145c32411a889008d9230b3e81",
      "8c7a711e322940d3b1fc2b22aa6c9187",
      "2fe3ce38cc37417caef2566682af4f12",
      "576000a2284a49d39c38058be30e72b1",
      "465158a4eea94324a227356d5e5fafed",
      "505ca684f6ef47cc8a47a05d18f0706a",
      "205fe1f6a92f463eb398b54304359009",
      "eae0467622d24863bb9b94142ae57a19",
      "d38e7d61ed9d4e2d8608b9f2f2f8de94",
      "2648cf55518a44a297303ace0d9d0657",
      "ea7d8ae2204b4cce9321ca8f23afc7bd",
      "cb76c894233d42bd8983768a162371b1",
      "4114d8fcbfb2413096f63006735dbc80",
      "0a041a8954ea487aacc085479efd4581",
      "62160327a2eb4b74a3a1a1dc593f3360",
      "0a066056b38e480c99adb901e0ae7463",
      "1c5ea8f08a5d415ca57cc8f7d2761b3b",
      "6b8f3358ae284400b744d70708990b6d",
      "1c1a5d68da494a08a77e2b9f2d31b657",
      "46da7d43ebad487fb34ab78f95a827ae"
     ]
    },
    "id": "BlLQU0Gfqpzh",
    "outputId": "fff37167-55ca-4d92-ebf6-f0143fb5e89d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer and base model...\n",
      "Model: TinyLlama/TinyLlama-1.1B-Chat-v1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1da899c00b7a4885ba41217496c3666f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4028636a403f4cc6a8d704013912de5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d0e4be80d2f4093874521743eb0a9f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2648cf55518a44a297303ace0d9d0657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tokenizer loaded\n",
      "  Vocab size: 32000\n",
      "  Pad token: </s>\n",
      " Ready to load base model (will load per task)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# CELL 6: Load Tokenizer and Base Model\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"Loading tokenizer and base model...\")\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print(\" Tokenizer loaded\")\n",
    "print(f\"  Vocab size: {len(tokenizer)}\")\n",
    "print(f\"  Pad token: {tokenizer.pad_token}\")\n",
    "\n",
    "# Note: We'll load the base model fresh for each task to avoid memory issues\n",
    "print(\" Ready to load base model (will load per task)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "f6cb728f9a26465885b2f8f4938963a5",
      "1fe30e9db32c437683d2046088a64a77",
      "8965e80c967c455db81c98d80611528c",
      "1301354583a34f1d82b90b59307f276c",
      "efa5f5cdc95b437c89ac40bbdf55b723",
      "9dc97792bd7243c3a4396d8b0e4f709a",
      "5c65830940f64c4bb4b8f93770cbba52",
      "059ee318145a46e4a3fd8b2e432ddd91",
      "4c7d99212de24c859dba83adc5d15519",
      "7ba75fe7b4974f42b0ec27cb60f60169",
      "5479eab5c23c4a6e93794baed6cd9f7b",
      "0c4792f4d16f44e49262f674a35f3073",
      "2f208d2f785b4332bbfb7808d4c0c5ef",
      "da63610760514d928f8465f327d8399f",
      "cb9d67cfac4440878f71655c93b65c9e",
      "7d960a20acb64ae6a5e934f0d3aad1f9",
      "1698974f463e481aa936daf29108aa1b",
      "69c6109d06d744f883278e9aa4debac7",
      "44301df706f5493e92391cf458dc559d",
      "18f13bb45b854ca4b44f276e2dbdc3eb",
      "36830c6b2f5c440091693f16690ee2d0",
      "298dc36e83a44dacaf0d73a22a2d6389",
      "ed45bedc0a8c4a988ace357be11173ef",
      "ffbcf4928cd04a0c9c369661215ee0be",
      "01690cf6af134a07bd73dec204cd7d51",
      "86a356b4ede04304ac149b86f23e1365",
      "8cb5d560b3384f66b8abeaa2ae9954cb",
      "7e5b740f95d44e9baede153da7c6bfe6",
      "b070c682e8a749cf96b9e87d3e5c06bd",
      "1edceea2a12f44e7b0c76a33c703afc7",
      "2691c4794b35411fbcbec29ccc0c05b4",
      "571d6a41a5784356b71f300b9bd46507",
      "d5d9bc43cd3e4c9086e4a30e6c17677a",
      "1b957fd27ea64de8af3febf39abd945c",
      "063d081a63e74040b07a14a589f34cf1",
      "667ae2016f914a18ab012b3a1fb90826",
      "2d163c7a29e245e0a117c692781cbd48",
      "b043b6a64f83483fa175cea5cefa8dca",
      "8bc9569f861842ee86ca65d4364a99e8",
      "d68fdf373e134fa08cb46bfd6730a462",
      "68b64c89f2414cf1897250819646ffa0",
      "561301e9e74f4367a36c362bca7948da",
      "87c9b446eba045f98016b7899a223ff8",
      "2daceef41da3443982e4abc763275c4c",
      "42ef394d62cb47988b4af17f745375fc",
      "847a6439c96e40f5a7d5974f67f51bad",
      "1758e36abdf6493dbc7f2fa21354f050",
      "1d1d6804badc4a3085d678b0faeb336e",
      "03816b1bbbc34dfbb1125b8cc20fd12a",
      "e39c48283cd94dc08d981915f24dec46",
      "c4e0a3eca72f4a1e855d3c085e442452",
      "b83fe4c62a1c45bb8f3dc88b44acbb89",
      "ff4f85868d3045b8af018d45399bcd62",
      "e2cc636f22964a8a97195e06038c3195",
      "cdf7f618095a4b4a8b94adafdba1ab9b",
      "af31b2265e7f40f0be2147132cd35889",
      "f919feb682424e94a4eb04a17c0706c7",
      "cdfe285222164ab98ac0d079d1b3cb31",
      "e2dad3bb804f49949d27f90f22d2aa02",
      "459b68a0991049ea97b695ecdb30c030",
      "351902fd59f54441ad0517184f8b4a45",
      "539c0d2b31274c47a37f04b641ce4226",
      "f2e9fee329cc4e4b8473af1d9aeb9764",
      "bd1a95f092d743c3af88ab6a850fc0a2",
      "2679e8b20a1b48dba189f52d59e9b6e9",
      "2f075f684c8049cabacf3b56f9fe407d",
      "e9af2936a79c436db67e5a4ada7d1471",
      "5887ac0871964c69885df65936158461",
      "e852dff5ec554ad19f9196ac64b8f81c",
      "dd8cf0076d974118b48a2fe7dbcb48a8",
      "b938a4512ddb4299908cc24ec79b6ec0",
      "a13b007c804d46a9bc0c84f9191a5adb",
      "04236872113a4148aad9e10219a0491b",
      "71774de7035040eba776b16434b416b1",
      "b564e9f3c67849fc987324ba939ca3bb",
      "14f6ab7b8c3f46bbb85dd09151b7692d",
      "58c3a8f9423e4c3e94df50325c63df01",
      "c73f468f5f894e6480f94d7accb26e38",
      "cb2019fd4b0c4954aa3a3d03eba1fc26",
      "5359456a813943b78aa7dd6b7da5a679",
      "9dcf42da4fc442f886d93088f2b0e449",
      "f8d26b09c0044ea8b547ec8216e38458",
      "7b2650023bb643c5ac482d0625b304ad",
      "eea27f43a6724f1cbe4f4214b466475a",
      "32b1ad29fece4059ab9c65d86c188622",
      "cc0b757bc2ee489b8d5af71955a95d02",
      "f042d0a24f6843ddb6ccdf66ebacf44a",
      "dc01ded06f0444caaaa75d945a5bf684",
      "225cba40b5464c888b10d3b9106d5747",
      "6c25cbfac4494e6196a4d71c7c250ab9",
      "be1a22d39dde4fdca805ea3f98bc6a0e",
      "7292122cda84465e8a347f4e90a8939d",
      "b772a49941fa4ad9bdd1d087cb05a637",
      "025893b928c74a3fabb394f7bd8f4489",
      "7d47029464214757bef31dc2353f6a41",
      "04a0fc799dbc4f55bd9041b295556132",
      "013a84d74023438bbcf1f8ca8bbfb8bc",
      "1914b37a498142c78d3c471d63cb6c1d",
      "b40b383c52404288a3517c5ed3f87156",
      "0e493a1fef304f019585f52f744a275c",
      "2b68030f95b64ab5819e4a69e57058ee",
      "31f6d5810aec454fa768339920ed6042",
      "834254be1c7444f482e355ba6f43815e",
      "3583ab317f3d49c6a0a25d7e883f39c5",
      "ce578920d5d241ac93bf89e6bd5d26fb",
      "1936370176ba461989e95e1b90013e53",
      "4a306c60203845d597861a085d920323",
      "d9f1e7c7a0504b0f86bc771152fb689a",
      "7a3734a00010483cb5ea307d6af1eec4",
      "b4be6e5b273c414d9a6c4e4bfa7c3493",
      "900b00eade194e979431d15b5d51b8a1",
      "2edc8a0226ef463a8e645a732a63da3d",
      "a22621465cf64dfaa866ba93b45d6313",
      "a1c72823968b4026974a8b003ee135a1",
      "3a0f97c7d17c48f5a87049692fb8e25f",
      "d553fd20a3994986960e59d92a406207",
      "e70217fd8807493c80bc078843410c5a",
      "49a60285433e49ed85191a4cdb69cffc",
      "b4db0166e59249f3879fe0acc02ae688",
      "13e3b98ac9554de98cbc48d66babadc1",
      "8fa471e278b7422f80e2fead01a07069",
      "bac978553aee4db0916f0000229f962f",
      "f7a91b5c60b24552825beb013f0cfeaf",
      "9845c7140bb04314ba6082e3fcf7371b",
      "d6899d2ef3f046e0a4bb4e44a899604c",
      "3521367331fc4f55b0677797929c9d39",
      "bbd271ad5b8e4a2ca5fff0054aab5da7",
      "cc2bdcfaef2a4d81a70f7c6fe739a529",
      "78536338aa2940e592da0a64ef959211",
      "4729344877a749f0a92399144bbaeb8b",
      "dbf28dd03f3d4eea8a2fed19c832ceb1",
      "152d1009823a446e9bdb875679be241d",
      "aa986604af2d45cfad676acbc5d503dd",
      "00953f83460143b191843214ee7023c9",
      "9a53c82bcb344418906761e620a61c8f",
      "6ccd342b00394b748515bc1d1330812b",
      "293bd7cd5bdc46bd909ee6a0d556289e",
      "3faf73959b064399acc0b86853c337b2",
      "317b4d1720494180888aa1cd4d92041d",
      "cf73817ac4a84ac0997a846853eb8b94",
      "a72dce09744b4d8faeb161be1b1455d8",
      "d0202d549a1f4d6b9e44885d7135c404",
      "a956f337e361424f81b3556373362cd7",
      "a127ce74080440cbafcf90046ff91dbb",
      "b08c0d8574f74609be062478ad77c77e",
      "597c2c3597fe4bf2b88fb22e36ee2596",
      "afd1bc9dd435492180362fcb88b35243",
      "356df0f4fdb74a1e97dd28fdef79f050",
      "5195355b51404a62be92da4452fad72b",
      "b0eeae40dc84413eb3439103f960d6cd",
      "0e4e3f4f4732483e87f572f12e1e3565",
      "4cd2f5928cfb468db046822a50807154",
      "09a39cea28fd44a2b4526dfb092297a5",
      "a4a7fa4c4df34287b68aa8ec79026d1c",
      "5d1818e6dedd4204bb16c13798c2f58b",
      "17478bc8ef4b40c5b43d9f18d0e6addf",
      "c8046d1cf56d494daeec8bfa58c6a761",
      "c6087e116fe14ae5a544dcd1d9cbae26",
      "11e71e7671ad47ce9ffbd832bba2f79b",
      "4879ff47ad0246539c79cf5edb9932d4",
      "9a9dc71184a34811b0bc1a05ad363660",
      "c440f09c6bcc4ca4ae134920dbcd003c",
      "a3e70bf6220f4ae2b076d06d542fafaa",
      "786237bd57a34b828465843da6bb33cc",
      "f27fe9ec01fe4d49ad9e0638fb7c1af7",
      "499b08bcf2144ea6b2a578250ee76907",
      "d0a22cb30df24e08830c376a8736a692",
      "78201241eac14c8098010788f2f81f96",
      "4d5ed79f32f7459992f0c0f3d5ac2a54",
      "02371b46537d45f3a61dde8f1876fa02",
      "5179e99e59b342b1af370e64ad3503c0",
      "d5fd76ce6df143ffa5defe13e46ded0d",
      "3e4c33ab260d47daa860bf744aae67c3",
      "c588717adc3b451c9204c5cc70238d30",
      "b3d1dd51a1fc4c7ba6a0654bc9716373",
      "836c5fdc8e3946c8b4c22357200241af",
      "b17ae539385c49d3ba35f70e327509c6",
      "083a61910cad4607a10c82f8fa5f8031",
      "84ac8cb7ba1d46ca94eff3f92ee9758d",
      "c0b0f70b455f4ed3bee3452e41a412d5",
      "b3acd472d36a410db17ad3dfa9674c23",
      "66572502441a4bb8a087302b610173b6",
      "c3b12c3f303a472a92ad7fd88a51891a",
      "d643b827d5134e36b32c7cdb4d080530",
      "22ade708a05340a98eced3643b9d235e",
      "21fba604afc7426184f4c6aa9d3d6ca2",
      "d669f09062504585b7e338f4332bd9f1",
      "696db8568e594036bcac37c7e8f6bf1e",
      "12ba6796610d4c05866f29ca30470e38",
      "352365b64b524439a5f0818203f211a8",
      "8b662d1a75ab4afd8a1487c1fb577fe7",
      "361594f320714caf8de4e6811dd42d87",
      "69eab7074ab14fccb4d4d16e501523d3",
      "4f3f3242d06d43cda0e3200f829b0ede",
      "ec940200e3e74c169af95c0174392e24",
      "3b4d76fdee0940919062448ce18790dc",
      "9d16290e8bd345fb8d2b1d17435c2025",
      "c9b1699ecdb74f6abf057945b264e33c",
      "240efc04eba54b86ade2f5e2a5776566",
      "8aa23b84dfe345799b7fc8e529418f62",
      "c8349e1071b44a94b3a04908ade632bf",
      "af8c43972b7443b98e6ee8c79436b633",
      "ed5678b151364368a552a7ade4eb0b26",
      "b0e841e72465413e9fec06b20622b144",
      "c40ca7086b43442882a124e33334c308",
      "5eacc05f472845be87476c3d65229b88",
      "060bb402e35743e6b28f2c3968c8ac9f",
      "42a81b077f96413484a2cae969c44484",
      "9412c28c84aa43448e2211cf70321449"
     ]
    },
    "id": "Og2DxJnxqp17",
    "outputId": "9875fdbf-9ddb-4c8c-c8fb-984ad3440011"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LOADING ALL TASK DATASETS\n",
      "======================================================================\n",
      "\n",
      "[1/4] Loading Medical Dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6cb728f9a26465885b2f8f4938963a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c4792f4d16f44e49262f674a35f3073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "medical_meadow_wikidoc_medical_flashcard(…):   0%|          | 0.00/17.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed45bedc0a8c4a988ace357be11173ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/33955 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing medical data (target: 5000 samples)...\n",
      "   Prepared 5000 medical samples\n",
      " Medical dataset ready: 5000 samples\n",
      "\n",
      "[2/4] Loading Code Dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b957fd27ea64de8af3febf39abd945c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/905 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42ef394d62cb47988b4af17f745375fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00001-8b6e212f3e1ece(…):   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af31b2265e7f40f0be2147132cd35889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/18612 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing code data (target: 5000 samples)...\n",
      "   Prepared 5000 code samples\n",
      " Code dataset ready: 5000 samples\n",
      "\n",
      "[3/4] Loading Math Dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9af2936a79c436db67e5a4ada7d1471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c73f468f5f894e6480f94d7accb26e38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "main/train-00000-of-00001.parquet:   0%|          | 0.00/2.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "225cba40b5464c888b10d3b9106d5747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "main/test-00000-of-00001.parquet:   0%|          | 0.00/419k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e493a1fef304f019585f52f744a275c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/7473 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "900b00eade194e979431d15b5d51b8a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1319 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing math data (target: 5000 samples)...\n",
      "   Prepared 5000 math samples\n",
      " Math dataset ready: 5000 samples\n",
      "\n",
      "[4/4] Loading Creative Writing Dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bac978553aee4db0916f0000229f962f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/837 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa986604af2d45cfad676acbc5d503dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00002-105e07cb0d1994(…):   0%|          | 0.00/272M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a127ce74080440cbafcf90046ff91dbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00001-of-00002-4fdb982c110564(…):   0%|          | 0.00/272M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d1818e6dedd4204bb16c13798c2f58b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/test-00000-of-00001-16503b0c26ed00c(…):   0%|          | 0.00/30.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "499b08bcf2144ea6b2a578250ee76907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/validation-00000-of-00001-137b93e1e(…):   0%|          | 0.00/30.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b17ae539385c49d3ba35f70e327509c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/272600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "696db8568e594036bcac37c7e8f6bf1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/15138 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "240efc04eba54b86ade2f5e2a5776566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/15620 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing creative data (target: 3000 samples)...\n",
      "   Prepared 3000 creative samples\n",
      " Creative dataset ready: 3000 samples\n",
      "\n",
      "======================================================================\n",
      " LOADED 4/4 DATASETS SUCCESSFULLY\n",
      "======================================================================\n",
      "  medical: 5000 samples\n",
      "  code: 5000 samples\n",
      "  math: 5000 samples\n",
      "  creative: 3000 samples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# CELL 7: Load All Task Datasets\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"LOADING ALL TASK DATASETS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "task_datasets = {}\n",
    "\n",
    "# Medical data\n",
    "print(\"\\n[1/4] Loading Medical Dataset...\")\n",
    "try:\n",
    "    ds = load_dataset(TASKS['medical'].dataset_name, split='train')\n",
    "    data = prepare_medical_data(ds, TASKS['medical'])\n",
    "    task_datasets['medical'] = TaskDataset(data, tokenizer, max_length=MAX_LENGTH)\n",
    "    print(f\" Medical dataset ready: {len(data)} samples\")\n",
    "except Exception as e:\n",
    "    print(f\" Medical data failed: {e}\")\n",
    "\n",
    "# Code data\n",
    "print(\"\\n[2/4] Loading Code Dataset...\")\n",
    "try:\n",
    "    ds = load_dataset(TASKS['code'].dataset_name, split='train')\n",
    "    data = prepare_code_data(ds, TASKS['code'])\n",
    "    task_datasets['code'] = TaskDataset(data, tokenizer, max_length=MAX_LENGTH)\n",
    "    print(f\" Code dataset ready: {len(data)} samples\")\n",
    "except Exception as e:\n",
    "    print(f\" Code data failed: {e}\")\n",
    "\n",
    "# Math data\n",
    "print(\"\\n[3/4] Loading Math Dataset...\")\n",
    "try:\n",
    "    ds = load_dataset(TASKS['math'].dataset_name, TASKS['math'].dataset_config, split='train')\n",
    "    data = prepare_math_data(ds, TASKS['math'])\n",
    "    task_datasets['math'] = TaskDataset(data, tokenizer, max_length=MAX_LENGTH)\n",
    "    print(f\" Math dataset ready: {len(data)} samples\")\n",
    "except Exception as e:\n",
    "    print(f\" Math data failed: {e}\")\n",
    "\n",
    "# Creative writing data\n",
    "print(\"\\n[4/4] Loading Creative Writing Dataset...\")\n",
    "try:\n",
    "    ds = load_dataset(TASKS['creative'].dataset_name, split='train')\n",
    "    data = prepare_creative_data(ds, TASKS['creative'])\n",
    "    task_datasets['creative'] = TaskDataset(data, tokenizer, max_length=MAX_LENGTH)\n",
    "    print(f\" Creative dataset ready: {len(data)} samples\")\n",
    "except Exception as e:\n",
    "    print(f\" Creative data failed: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\" LOADED {len(task_datasets)}/4 DATASETS SUCCESSFULLY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Verify datasets\n",
    "for task_name, dataset in task_datasets.items():\n",
    "    print(f\"  {task_name}: {len(dataset)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yml-RD6dqp5e",
    "outputId": "a7b59859-c8ba-467d-ab0a-098d4c63aa01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training function defined\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# CELL 8: Define Training Function\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "def train_lora_expert(task_name: str, task_config: TaskConfig, tokenizer, dataset):\n",
    "    \"\"\"Train a single LoRA expert for a specific task\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"TRAINING LORA EXPERT: {task_name.upper()}\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    # Load fresh base model\n",
    "    print(\"Loading base model...\")\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "    print(\" Base model loaded\")\n",
    "\n",
    "    # Configure LoRA\n",
    "    print(\"Configuring LoRA...\")\n",
    "    lora_config = LoraConfig(\n",
    "        r=task_config.lora_r,\n",
    "        lora_alpha=task_config.lora_alpha,\n",
    "        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
    "        lora_dropout=task_config.lora_dropout,\n",
    "        bias=\"none\",\n",
    "        task_type=TaskType.CAUSAL_LM\n",
    "    )\n",
    "\n",
    "    # Create PEFT model\n",
    "    model = get_peft_model(base_model, lora_config)\n",
    "    print(\" LoRA adapter attached\")\n",
    "    model.print_trainable_parameters()\n",
    "\n",
    "    # Training arguments\n",
    "    output_dir = f\"./lora_experts/{task_name}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=NUM_EPOCHS,\n",
    "        per_device_train_batch_size=BATCH_SIZE,\n",
    "        gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        warmup_steps=WARMUP_STEPS,\n",
    "        fp16=torch.cuda.is_available(),\n",
    "        logging_steps=50,\n",
    "        save_strategy=\"epoch\",\n",
    "        save_total_limit=2,\n",
    "        report_to=\"none\",\n",
    "        remove_unused_columns=False,\n",
    "        dataloader_pin_memory=False,\n",
    "    )\n",
    "\n",
    "    # Create trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=dataset,\n",
    "        data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    "    )\n",
    "\n",
    "    # Train\n",
    "    print(\"\\nStarting training...\")\n",
    "    trainer.train()\n",
    "\n",
    "    # Save LoRA weights\n",
    "    print(\"\\nSaving LoRA adapter...\")\n",
    "    model.save_pretrained(output_dir)\n",
    "    print(f\" LoRA expert saved to: {output_dir}\")\n",
    "\n",
    "    # Clean up\n",
    "    del model\n",
    "    del base_model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return output_dir\n",
    "\n",
    "print(\"Training function defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "d89e8334ba5640fa8a0117d58c56b1c9",
      "28b5fa990a004f08bdcacaf7b163b740",
      "23ec9bc437724b5ca816469d5e4ccf7b",
      "dc9e3e1548874b0f8233ffb8424fa42b",
      "f5c4c73bf1ca443b8aab6e64675807b8",
      "00e91878e5f8423193e74a64963e634f",
      "34b863a3bc4b406f8c9f257bd23293f3",
      "afcd4735426f4c2da54430ce1e2b6562",
      "3d9207b64e9f4c22824e141b8d8d9e54",
      "78888c8029534614a9577f90c2abbe8d",
      "af52687264914b44bc8da845dd217da1",
      "7c03c197759c4d6cbb4b494e734e913c",
      "a42a0863bb4b44a2b7de13dc31b7eac3",
      "8102410b9dbf4d0a9481b7ee67e5f1a9",
      "19f87764b1a54f20946003a0b1a3f4cb",
      "ac722008ccd44c4b9751fdb6aa356c5a",
      "d4a41567e2224433b48a402ad49514a2",
      "56c410399b1d4a2c980682add632f87f",
      "a03feea71ef84c1da18ed6681605d102",
      "14dea810e9154ded8bfcfa83b1947eff",
      "409b9d27598040d790dddc30e69e691c",
      "ac26b118a4ce4a2089dc6578fb3ebf55",
      "a4ffd4473435469dbd7524ec5036ddd2",
      "27c22a59578f4f56aacf8b339928e2e3",
      "31774fa9d5704f2d8bbd2205bd662c11",
      "e70737ed41994460bb8557e0e6f2145d",
      "c018a0c14b7e4ba09225994171a8d24f",
      "5855df87eea8443c8ecca004d4bafeb6",
      "e51ada1a2a85474baacd742dfd8dbe25",
      "f65ac79c2a6d4b60aa75ec2c784c386e",
      "a328135f464c46cd90e2cc54b79cd569",
      "a7d1e66cef3a41d4a9c1d2246fe3791d",
      "382e21336d73418caaea21bee806ff69"
     ]
    },
    "id": "quULGu89q84x",
    "outputId": "f5ec9dff-3704-44e1-9b23-68f88d6f2227"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TRAINING LORA EXPERT: MEDICAL\n",
      "======================================================================\n",
      "Loading base model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d89e8334ba5640fa8a0117d58c56b1c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c03c197759c4d6cbb4b494e734e913c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4ffd4473435469dbd7524ec5036ddd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Base model loaded\n",
      "Configuring LoRA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " LoRA adapter attached\n",
      "trainable params: 4,505,600 || all params: 1,104,553,984 || trainable%: 0.4079\n",
      "\n",
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='939' max='939' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [939/939 43:02, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.193200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.958400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.946900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.931800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.918300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.902400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.886800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.865300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.863200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.863300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.858300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.841600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.840700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.804900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.801200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.794200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.790400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.786200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving LoRA adapter...\n",
      " LoRA expert saved to: ./lora_experts/medical\n",
      "\n",
      " MEDICAL EXPERT TRAINING COMPLETE ✓✓✓\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# CELL 9: Train Medical Expert\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "if 'medical' in task_datasets:\n",
    "    medical_path = train_lora_expert(\n",
    "        'medical',\n",
    "        TASKS['medical'],\n",
    "        tokenizer,\n",
    "        task_datasets['medical']\n",
    "    )\n",
    "    print(f\"\\n MEDICAL EXPERT TRAINING COMPLETE\")\n",
    "else:\n",
    "    print(\" Medical dataset not available, skipping...\")\n",
    "    medical_path = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 954
    },
    "id": "buZqJbAjrBG9",
    "outputId": "2335f60d-b854-4ab7-f9d0-6cc02696ccdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TRAINING LORA EXPERT: CODE\n",
      "======================================================================\n",
      "Loading base model...\n",
      " Base model loaded\n",
      "Configuring LoRA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " LoRA adapter attached\n",
      "trainable params: 4,505,600 || all params: 1,104,553,984 || trainable%: 0.4079\n",
      "\n",
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='939' max='939' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [939/939 43:18, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.934900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.732000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.704600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.711400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.696500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.685300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.684300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.670400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.638200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.663600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.657900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.624400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.625600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.638300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.642900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.611700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.625800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving LoRA adapter...\n",
      " LoRA expert saved to: ./lora_experts/code\n",
      "\n",
      " CODE EXPERT TRAINING COMPLETE \n"
     ]
    }
   ],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# CELL 10: Train Code Expert\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "if 'code' in task_datasets:\n",
    "    code_path = train_lora_expert(\n",
    "        'code',\n",
    "        TASKS['code'],\n",
    "        tokenizer,\n",
    "        task_datasets['code']\n",
    "    )\n",
    "    print(f\"\\n CODE EXPERT TRAINING COMPLETE \")\n",
    "else:\n",
    "    print(\" Code dataset not available, skipping...\")\n",
    "    code_path = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "H6by2mz5rB8Q",
    "outputId": "6e1488f0-2611-4933-aad8-4c241afbb3b1"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TRAINING LORA EXPERT: MATH\n",
      "======================================================================\n",
      "Loading base model...\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Base model loaded\n",
      "Configuring LoRA...\n",
      " LoRA adapter attached\n",
      "trainable params: 4,505,600 || all params: 1,104,553,984 || trainable%: 0.4079\n",
      "\n",
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='737' max='939' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [737/939 34:03 < 09:21, 0.36 it/s, Epoch 2.35/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.442500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.026500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.968600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.942600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.936000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.929400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.902700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.896300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.881400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.886900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.863800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.874800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.862700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.837700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='939' max='939' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [939/939 43:28, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.442500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.026500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.968600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.942600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.936000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.929400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.902700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.896300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.881400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.886900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.863800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.874800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.862700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.837700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.836800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.843400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.841900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.842100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving LoRA adapter...\n",
      " LoRA expert saved to: ./lora_experts/math\n",
      "\n",
      " MATH EXPERT TRAINING COMPLETE \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# CELL 11: Train Math Expert\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "if 'math' in task_datasets:\n",
    "    math_path = train_lora_expert(\n",
    "        'math',\n",
    "        TASKS['math'],\n",
    "        tokenizer,\n",
    "        task_datasets['math']\n",
    "    )\n",
    "    print(f\"\\n MATH EXPERT TRAINING COMPLETE \")\n",
    "else:\n",
    "    print(\"Math dataset not available, skipping...\")\n",
    "    math_path = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 735
    },
    "id": "kbA9wtqqrBJd",
    "outputId": "de8bca30-8a03-4124-8b54-40c73123aa7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TRAINING LORA EXPERT: CREATIVE\n",
      "======================================================================\n",
      "Loading base model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Base model loaded\n",
      "Configuring LoRA...\n",
      " LoRA adapter attached\n",
      "trainable params: 4,505,600 || all params: 1,104,553,984 || trainable%: 0.4079\n",
      "\n",
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [564/564 26:44, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.763400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.493400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.460200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.425600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>2.430200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.402700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.395300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.414600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.341300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.394400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>2.397900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving LoRA adapter...\n",
      " LoRA expert saved to: ./lora_experts/creative\n",
      "\n",
      " CREATIVE WRITING EXPERT TRAINING COMPLETE \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# CELL 12: Train Creative Writing Expert\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "if 'creative' in task_datasets:\n",
    "    creative_path = train_lora_expert(\n",
    "        'creative',\n",
    "        TASKS['creative'],\n",
    "        tokenizer,\n",
    "        task_datasets['creative']\n",
    "    )\n",
    "    print(f\"\\n CREATIVE WRITING EXPERT TRAINING COMPLETE \")\n",
    "else:\n",
    "    print(\"Creative dataset not available, skipping...\")\n",
    "    creative_path = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2bhQX9ysrBLy",
    "outputId": "c82482af-f42b-4e00-8760-070580770cae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      " ALL LORA EXPERTS TRAINING COMPLETE! \n",
      "======================================================================\n",
      "\n",
      " Training Summary:\n",
      "   Experts trained: 4/4\n",
      "   Base model: TinyLlama/TinyLlama-1.1B-Chat-v1.0\n",
      "   LoRA rank: 16\n",
      "   Training epochs: 3\n",
      "\n",
      " Saved files:\n",
      "  • LoRA experts: ./lora_experts/\n",
      "    - medical: ./lora_experts/medical\n",
      "    - code: ./lora_experts/code\n",
      "    - math: ./lora_experts/math\n",
      "    - creative: ./lora_experts/creative\n",
      "   Configuration: ./experts_config.json\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# CELL 13: Save Configuration & Summary\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "# Collect trained paths\n",
    "lora_paths = {}\n",
    "if medical_path:\n",
    "    lora_paths['medical'] = medical_path\n",
    "if code_path:\n",
    "    lora_paths['code'] = code_path\n",
    "if math_path:\n",
    "    lora_paths['math'] = math_path\n",
    "if creative_path:\n",
    "    lora_paths['creative'] = creative_path\n",
    "\n",
    "# Save configuration\n",
    "config = {\n",
    "    \"model_name\": MODEL_NAME,\n",
    "    \"max_length\": MAX_LENGTH,\n",
    "    \"tasks\": {k: {\n",
    "        \"name\": v.name,\n",
    "        \"lora_r\": v.lora_r,\n",
    "        \"lora_alpha\": v.lora_alpha,\n",
    "        \"lora_dropout\": v.lora_dropout,\n",
    "        \"prompt_template\": v.prompt_template\n",
    "    } for k, v in TASKS.items()},\n",
    "    \"lora_paths\": lora_paths,\n",
    "    \"training_config\": {\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"gradient_accumulation_steps\": GRADIENT_ACCUMULATION_STEPS,\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "        \"num_epochs\": NUM_EPOCHS\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(\"./experts_config.json\", \"w\") as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" ALL LORA EXPERTS TRAINING COMPLETE! \")\n",
    "print(\"=\"*70)\n",
    "print(\"\\n Training Summary:\")\n",
    "print(f\"   Experts trained: {len(lora_paths)}/4\")\n",
    "print(f\"   Base model: {MODEL_NAME}\")\n",
    "print(f\"   LoRA rank: {TASKS['medical'].lora_r}\")\n",
    "print(f\"   Training epochs: {NUM_EPOCHS}\")\n",
    "print(\"\\n Saved files:\")\n",
    "print(f\"  • LoRA experts: ./lora_experts/\")\n",
    "for task, path in lora_paths.items():\n",
    "    print(f\"    - {task}: {path}\")\n",
    "print(f\"   Configuration: ./experts_config.json\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "id": "dq6Y9U86rBOL",
    "outputId": "d0e037a5-7c8e-4428-a49e-fc1e7ebb59ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating archive...\n",
      "Downloading...\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_8c4e8589-4b84-466e-8665-2d36e9ae3ccb\", \"lora_experts.zip\", 470447768)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_a92c6633-2101-432e-84c5-3edaa82506f2\", \"experts_config.json\", 1233)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp Download complete!\n",
      "\n",
      " Tip: Uncomment Cell 14 to download trained models to your computer!\n"
     ]
    }
   ],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# CELL 14: Download Trained Models (Optional)\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "# Uncomment to download all artifacts to your local machine\n",
    "\n",
    "from google.colab import files\n",
    "import shutil\n",
    "#\n",
    "# # Create zip archive\n",
    "print(\"Creating archive...\")\n",
    "shutil.make_archive('lora_experts', 'zip', './lora_experts')\n",
    "#\n",
    "# # Download\n",
    "print(\"Downloading...\")\n",
    "files.download('lora_experts.zip')\n",
    "files.download('experts_config.json')\n",
    "#\n",
    "print(\"comp Download complete!\")\n",
    "\n",
    "print(\"\\n Tip: Uncomment Cell 14 to download trained models to your computer!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WIJzqk8TRRyS",
    "outputId": "3247c8ed-6667-4ec8-e53d-63b347083531"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4NmEEAUWqjy9",
    "outputId": "ecbbe600-c1f1-4c46-ba51-c4c36b3129bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Testing MEDICAL Expert\n",
      "======================================================================\n",
      "Loading models...\n",
      "\n",
      " Prompt: ### Medical Question:\n",
      "What are the symptoms of diabetes?\n",
      "\n",
      "### Answer:\n",
      "\n",
      "\n",
      " Response:\n",
      "### Medical Question:\n",
      "What are the symptoms of diabetes?\n",
      "\n",
      "### Answer:\n",
      "Diabetes is a chronic disease that is characterized by the presence of hyperglycemia (high blood sugar) and the absence of insulin. These symptoms can be seen in different parts of the body depending on the severity of the condition. Some of the symptoms of diabetes include fatigue, weakness, blurry vision, and swelling in the legs and feet. In more severe cases, diabetes can also cause damage to the retina of the eye and cause vision loss. Other symptoms of diabetes can include nerve pain, joint pain, and urinary tract infections. Diabetes is a serious condition that requires regular monitoring and treatment to manage its effects on\n",
      "\n",
      "======================================================================\n",
      "Testing CODE Expert\n",
      "======================================================================\n",
      "Loading models...\n",
      "\n",
      " Prompt: ### Instruction:\n",
      "Write a function to reverse a string\n",
      "\n",
      "### Code:\n",
      "\n",
      "\n",
      " Response:\n",
      "### Instruction:\n",
      "Write a function to reverse a string\n",
      "\n",
      "### Code:\n",
      "def reverse_string(string):\n",
      "    return string[::-1]\n",
      "  \n",
      "print(reverse_string(\"Hello World!\")) # Output:!dlroWolleN\n",
      "\n",
      "# Python 3 program to reverse a string\n",
      "string = \"Hello World!\"\n",
      "print(reverse_string(string)) # Output:!dlroWolleN\n",
      "\n",
      "# Python 2 program to reverse a string\n",
      "string = \"Hello World!\"\n",
      "print(string[::-1]) # Output:!dlroWolleN\n",
      "\n",
      "# Output:\n",
      "# Hello World!\n",
      "# World!\n",
      "# !dlroWolleN\n",
      "# ----------------------------------------------------------------------------------------------------------------------\n",
      "# Python\n",
      "\n",
      " Tip: Uncomment Cell 15 to test individual experts!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "# CELL 15: Quick Test (Optional)\n",
    "# ═══════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "# Quick test of a trained expert\n",
    "def quick_test_expert(task_name: str, test_prompt: str):\n",
    "    \"\"\"Quick test of a trained expert\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Testing {task_name.upper()} Expert\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    from peft import PeftModel\n",
    "\n",
    "    # Load base model\n",
    "    print(\"Loading models...\")\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "\n",
    "    # Load LoRA adapter\n",
    "    model = PeftModel.from_pretrained(base_model, f\"./lora_experts/{task_name}\")\n",
    "    model.eval()\n",
    "\n",
    "    # Generate\n",
    "    print(f\"\\n Prompt: {test_prompt}\")\n",
    "    inputs = tokenizer(test_prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=150,\n",
    "            temperature=0.7,\n",
    "            do_sample=True,\n",
    "            top_p=0.95,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    print(f\"\\n Response:\\n{response}\")\n",
    "\n",
    "    # Cleanup\n",
    "    del model\n",
    "    del base_model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Uncomment to test an expert:\n",
    "quick_test_expert('medical', '### Medical Question:\\nWhat are the symptoms of diabetes?\\n\\n### Answer:\\n')\n",
    "quick_test_expert('code', '### Instruction:\\nWrite a function to reverse a string\\n\\n### Code:\\n')\n",
    "\n",
    "print(\"\\n Tip: Uncomment Cell 15 to test individual experts!\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
